{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unveiling Insights into the Hong Kong YouTube Scene: A Data-Driven Exploration of Top Channels and User Sentiment\n",
    "\n",
    "## by Patty Lau\n",
    "\n",
    "### Description: This is an exploratory data analysis project focused on the most-subscribed YouTube video channels in Hong Kong. A range of tools and techniques were utilised to build a data pipeline and perform sentiment analysis on video comments. Data visualizations were also created to enhance insights and communicate findings.\n",
    "\n",
    "### Tech Stack: Python, Jupyter Notebook, MongoDB, Google Cloud Platform Compute Engine, Big Query, Natural Language API, Apache Spark, Microsoft Power BI, Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import datetime as dt\n",
    "import isodate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Connect to locatlhost and port 27017\n",
    "client = MongoClient(os.getenv('MONGODB_URI') or 'mongodb://localhost:27017')\n",
    "\n",
    "# Choose the MongoDB database\n",
    "db = client.youtubedataapi0416\n",
    "\n",
    "# Connect to the posgresql data warehouse\n",
    "POSTGRES_DB = os.getenv('POSTGRES_DB')\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collect data from YouTube API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Sample Python code for youtube.channels.list\n",
    "# See instructions for running these code samples locally:\n",
    "# https://developers.google.com/explorer-help/code-samples#python\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "\n",
    "# Get credentials and create an API client\n",
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coffeeæ—èŠŠå¦¤ (ID: UCxCZqbizSsnntlz6w0fN8hA)\n",
      "Fanny Wang - Topic (ID: UCTEy93F0GaoP_ycEIgqWjbg)\n",
      "Stephy Tang - Topic (ID: UCtiL38iHIIUi10k_zbpqCRQ)\n"
     ]
    }
   ],
   "source": [
    "# search for channels\n",
    "\n",
    "# Define the search parameters\n",
    "search_query = [\"Emi Wong\", \"Coffee Lam\"]\n",
    "request = youtube.search().list(\n",
    "    q=\",\".join(search_query),\n",
    "    type=\"channel\",\n",
    "    part=\"id,snippet\",\n",
    "    maxResults=10\n",
    ")\n",
    "\n",
    "# Execute the search and print the results\n",
    "next_page_token = ''\n",
    "while True:\n",
    "    response = request.execute()\n",
    "    for channel in response['items']:\n",
    "        channel_id = channel['id']['channelId']\n",
    "        channel_name = channel['snippet']['title']\n",
    "        print(f\"{channel_name} (ID: {channel_id})\")\n",
    "\n",
    "    # Check if there are more pages of results\n",
    "    if 'nextPageToken' in response:\n",
    "        next_page_token = response['nextPageToken']\n",
    "        request = youtube.search().list(\n",
    "            q=\",\".join(search_query),\n",
    "            type=\"channel\",\n",
    "            part=\"id,snippet\",\n",
    "            maxResults=10,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to get channel stats\n",
    "\n",
    "def get_channel_stats(youtube, channel_ids):\n",
    "    all_channel_stats = []  # list to store all channel stats\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # loop through each channel id\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelId=response['items'][i]['id'],\n",
    "                    ChannelTitle=response['items'][i]['snippet']['title'],\n",
    "                    subscribers=int(\n",
    "                        response['items'][i]['statistics']['subscriberCount']),\n",
    "                    totalViews=int(response['items'][i]\n",
    "                                   ['statistics']['viewCount']),\n",
    "                    totalVideos=int(response['items']\n",
    "                                    [i]['statistics']['videoCount']),\n",
    "                    channelPublishedAt=response['items'][i]['snippet']['publishedAt'],\n",
    "                    playlistId=response['items'][i]['contentDetails']['relatedPlaylists']['uploads'],\n",
    "                    DataRetrievedAt=dt.datetime.now().isoformat())\n",
    "        all_channel_stats.append(data)\n",
    "\n",
    "        # Write data to MongoDB\n",
    "        # db.top5hkchannelsinfo.insert_one(data)\n",
    "    return all_channel_stats  # return all channel stats for each channel ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get videoIds from playlistId\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50)\n",
    "    response = request.execute()\n",
    "\n",
    "    video_ids = []\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    havePages = True\n",
    "\n",
    "    while havePages:\n",
    "        if next_page_token is None:\n",
    "            havePages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token)\n",
    "            response = request.execute()\n",
    "\n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]\n",
    "                                 ['contentDetails']['videoId'])\n",
    "\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            # Write data to MongoDB\n",
    "    # db.allvideoids.insert_one(dict(playlistId=playlist_id,videoId=video_ids))\n",
    "\n",
    "    return video_ids  # return list of videoIds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get video details\n",
    "def get_video_details(youtube, video_ids):\n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            if 'tags' not in video['snippet'].keys():\n",
    "                video['snippet']['tags'] = None\n",
    "            if 'likeCount' not in video['statistics'].keys():\n",
    "                video['statistics']['likeCount'] = 0\n",
    "            if 'commentCount' not in video['statistics'].keys():\n",
    "                video['statistics']['commentCount'] = 0\n",
    "            # insert video id\n",
    "            video_info = dict(VideoId=video['id'],\n",
    "                              ChannelTitle=video['snippet']['channelTitle'],\n",
    "                              VideoTitle=video['snippet']['title'],\n",
    "                              Description=video['snippet']['description'],\n",
    "                              Tags=video['snippet']['tags'],\n",
    "                              Published_date=video['snippet']['publishedAt'],\n",
    "                              Views=int(video['statistics']['viewCount']),\n",
    "                              Likes=int(video['statistics']['likeCount']),\n",
    "                              Comments=int(\n",
    "                                  video['statistics']['commentCount']),\n",
    "                              Duration=isodate.parse_duration(\n",
    "                                  video['contentDetails']['duration']).total_seconds(),\n",
    "                              Definition=video['contentDetails']['definition'],\n",
    "                              Caption=video['contentDetails']['caption'],\n",
    "                              DataRetrievedAt=dt.datetime.now().isoformat()\n",
    "                              )\n",
    "            all_video_info.append(video_info)\n",
    "            # db.allvideoinfo.insert_one(video_info)\n",
    "    return all_video_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get video comments\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "\n",
    "    all_comments_info = []\n",
    "    all_disabled_comments_info = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100  # set max number of comments to retrieve\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            comments_info = dict(videoId=video_id,\n",
    "                                 commentText=[comment['snippet']['topLevelComment']\n",
    "                                              ['snippet']['textOriginal'] for comment in response['items']],\n",
    "                                 commentPublishedAt=[comment['snippet']['topLevelComment']['snippet']\n",
    "                                                     ['publishedAt'] for comment in response['items']],\n",
    "                                 likeCount=[int(comment['snippet']['topLevelComment']['snippet']\n",
    "                                                    ['likeCount']) for comment in response['items']],\n",
    "                                 DataRetrievedAt=dt.datetime.now().isoformat()\n",
    "                                 )\n",
    "            all_comments_info.append(comments_info)\n",
    "            # Write data to MongoDB\n",
    "            # db.allcommentsinfo.insert_one(comments_info)\n",
    "\n",
    "        except Exception as e:\n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print(e)\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "\n",
    "            disabled_comments_info = dict(videoId=video_id, commentText=\"disabled comments\",\n",
    "                                          commentPublishedAt=\"disabled comments\",\n",
    "                                          likeCount=\"disabled comments\",\n",
    "                                          DataRetrievedAt=dt.datetime.now().isoformat()\n",
    "                                          )\n",
    "            all_disabled_comments_info.append(disabled_comments_info)\n",
    "            # db.disabledcommentsinfo.insert_one(disabled_comments_info)\n",
    "    return all_comments_info, all_disabled_comments_info\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert raw data collected to mongoDB and display temperorary dataframe with Pandas\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get channel statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UCvGEK5_U-kLgO6-AMDPeTUQ',  # Emi Wong\n",
    "               'UCxCZqbizSsnntlz6w0fN8hA',  # Coffee Lam\n",
    "               'UCXnWjmQ8BDE0sDIeZLK5yJg',  # é» Cook Guide\n",
    "               'UC4nsi0oM9WBNFv1RdLh3c2g',  # JASON816\n",
    "               'UCDpK1rg5I9Zc3ToY13vbR3w'  # ç¬‘æ³¢å­\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = get_channel_stats(youtube, channel_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelId</th>\n",
       "      <th>ChannelTitle</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>totalVideos</th>\n",
       "      <th>channelPublishedAt</th>\n",
       "      <th>playlistId</th>\n",
       "      <th>DataRetrievedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCDpK1rg5I9Zc3ToY13vbR3w</td>\n",
       "      <td>ç¬‘æ³¢å­</td>\n",
       "      <td>936000</td>\n",
       "      <td>1051897493</td>\n",
       "      <td>4354</td>\n",
       "      <td>2006-09-09T19:59:59Z</td>\n",
       "      <td>UUDpK1rg5I9Zc3ToY13vbR3w</td>\n",
       "      <td>2023-04-16T09:38:02.175488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC4nsi0oM9WBNFv1RdLh3c2g</td>\n",
       "      <td>JASON</td>\n",
       "      <td>1040000</td>\n",
       "      <td>521248369</td>\n",
       "      <td>2955</td>\n",
       "      <td>2013-06-16T13:50:59Z</td>\n",
       "      <td>UU4nsi0oM9WBNFv1RdLh3c2g</td>\n",
       "      <td>2023-04-16T09:38:02.175504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCXnWjmQ8BDE0sDIeZLK5yJg</td>\n",
       "      <td>é» Cook Guide</td>\n",
       "      <td>1110000</td>\n",
       "      <td>202603292</td>\n",
       "      <td>1356</td>\n",
       "      <td>2014-02-07T15:44:04Z</td>\n",
       "      <td>UUXnWjmQ8BDE0sDIeZLK5yJg</td>\n",
       "      <td>2023-04-16T09:38:02.175526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCvGEK5_U-kLgO6-AMDPeTUQ</td>\n",
       "      <td>emi wong</td>\n",
       "      <td>5960000</td>\n",
       "      <td>787128269</td>\n",
       "      <td>442</td>\n",
       "      <td>2014-11-02T14:43:34Z</td>\n",
       "      <td>UUvGEK5_U-kLgO6-AMDPeTUQ</td>\n",
       "      <td>2023-04-16T09:38:02.175529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCxCZqbizSsnntlz6w0fN8hA</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>1700000</td>\n",
       "      <td>261803319</td>\n",
       "      <td>353</td>\n",
       "      <td>2015-06-02T07:09:15Z</td>\n",
       "      <td>UUxCZqbizSsnntlz6w0fN8hA</td>\n",
       "      <td>2023-04-16T09:38:02.175533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  channelId  ChannelTitle  subscribers  totalViews  \\\n",
       "0  UCDpK1rg5I9Zc3ToY13vbR3w           ç¬‘æ³¢å­       936000  1051897493   \n",
       "1  UC4nsi0oM9WBNFv1RdLh3c2g         JASON      1040000   521248369   \n",
       "2  UCXnWjmQ8BDE0sDIeZLK5yJg  é» Cook Guide      1110000   202603292   \n",
       "3  UCvGEK5_U-kLgO6-AMDPeTUQ      emi wong      5960000   787128269   \n",
       "4  UCxCZqbizSsnntlz6w0fN8hA     Coffeeæ—èŠŠå¦¤      1700000   261803319   \n",
       "\n",
       "   totalVideos    channelPublishedAt                playlistId  \\\n",
       "0         4354  2006-09-09T19:59:59Z  UUDpK1rg5I9Zc3ToY13vbR3w   \n",
       "1         2955  2013-06-16T13:50:59Z  UU4nsi0oM9WBNFv1RdLh3c2g   \n",
       "2         1356  2014-02-07T15:44:04Z  UUXnWjmQ8BDE0sDIeZLK5yJg   \n",
       "3          442  2014-11-02T14:43:34Z  UUvGEK5_U-kLgO6-AMDPeTUQ   \n",
       "4          353  2015-06-02T07:09:15Z  UUxCZqbizSsnntlz6w0fN8hA   \n",
       "\n",
       "              DataRetrievedAt  \n",
       "0  2023-04-16T09:38:02.175488  \n",
       "1  2023-04-16T09:38:02.175504  \n",
       "2  2023-04-16T09:38:02.175526  \n",
       "3  2023-04-16T09:38:02.175529  \n",
       "4  2023-04-16T09:38:02.175533  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(channel_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f1488c3ac20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.top5hkchannelsinfo.insert_many(channel_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get video ids from playlist id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = \"UUxCZqbizSsnntlz6w0fN8hA\"  # emi\n",
    "video_ids = get_video_ids(youtube, playlist_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f1424b1a260>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.allvideoids.insert_one(dict(playlistId=playlist_id, videoId=video_ids))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get video details from video ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoId</th>\n",
       "      <th>ChannelTitle</th>\n",
       "      <th>VideoTitle</th>\n",
       "      <th>Description</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Published_date</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Caption</th>\n",
       "      <th>DataRetrievedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WxTxeyqRM4E</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>è¶ç€å…’ç«¥ç¯€åŒå¤§å®¶å®£ä½ˆCoffeeSweatä»£è¨€äººğŸŒŸé™³ä¼¯å€‹fdï½ç¿Ÿä¼¯ğŸ˜!! #coffeesw...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-04T09:18:00Z</td>\n",
       "      <td>10622</td>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:16.977984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ibZ6t_lTTIA</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>28åˆ†é˜ å¥³æ€§æ—¥å¸¸é¤Šç”Ÿç‘œä¼½ï½œç”±å…§åˆ°å¤–ä¿é¤Šï½œå…¨èº«ä¿å¥æ‹‰ç­‹â™¥ï¸æ„›è‡ªå·±â™¥ï¸ï½œå­•å©¦éƒ½èƒ½åš</td>\n",
       "      <td>On coffee lam\\nWrap around long sleeve- white\\...</td>\n",
       "      <td>[coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...</td>\n",
       "      <td>2023-04-01T07:50:53Z</td>\n",
       "      <td>55057</td>\n",
       "      <td>1937</td>\n",
       "      <td>123</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:16.978017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1AqSRo535vs</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>22åˆ†é˜ æ¥µæœ‰æ•ˆå…¨èº«å±€éƒ¨è‚Œè‚‰è¨“ç·´ï½œç”¨body weightå¢è‚Œï½œ14å¤©è‚ŒåŠ›æŒ‘æˆ°ğŸ”¥</td>\n",
       "      <td>On Coffee Lam\\nChic Sports Braï¼ˆMercury Greyï¼‰\\n...</td>\n",
       "      <td>[coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...</td>\n",
       "      <td>2023-03-20T04:51:15Z</td>\n",
       "      <td>95416</td>\n",
       "      <td>2072</td>\n",
       "      <td>156</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:16.978034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ZLyuY01Dqo</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>æ¯å¤©éƒ½è¦ç©¿ç€è…°å°å»ç‚ºè…°éƒ¨å¡‘å½¢ğŸ”¥</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-18T04:44:13Z</td>\n",
       "      <td>15493</td>\n",
       "      <td>206</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:16.978050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pmOdWGRcNvc</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>CoffeeSweat 2023 Spring Collectionâ™¥ï¸</td>\n",
       "      <td>www.CoffeeSweat.com</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-13T08:52:26Z</td>\n",
       "      <td>8326</td>\n",
       "      <td>231</td>\n",
       "      <td>5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:16.978065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>11tdiQZb-BM</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>COFFEE YOGA EP4. å‡CUPç‘œçˆï¼å¹«ä½ æ¸›è‚šè…©ï¼</td>\n",
       "      <td>ä¸€é€£å…©é›†å‡ç´šç‘œçˆç¯‡ï¼Œç¬¬ä¸€é›†å…ˆæ•™å¤§å®¶æ¸›ï¼è‚šï¼è…© ï¼å…ˆæœ‰å…©å€‹å‹•ä½œæ”¹å–„å¯’èƒŒå•é¡Œï¼Œå†åŠ å…©å€‹å‹•ä½œåŒå¹«ä½ ...</td>\n",
       "      <td>[coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...</td>\n",
       "      <td>2015-07-26T03:08:00Z</td>\n",
       "      <td>146074</td>\n",
       "      <td>1330</td>\n",
       "      <td>33</td>\n",
       "      <td>200.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:18.180162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>SUy3-htFkys</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>COFFEE YOGA EP3. ç‘œçˆç”·å¥³å¤§ä¸åŒ</td>\n",
       "      <td>ç”·ä»”å¥³ä»”åšç‘œçˆå‹•ä½œå„æœ‰å„å›°é›£ï¼Œä»Šæ¬¡å°±åŒå¤§å®¶ç°¡å–®ç¤ºç¯„ä¸‹å•¦ï¼\\næƒ³å­¸æ›´å¤šï¼Œè¨˜å¾—SUBSCRIBE...</td>\n",
       "      <td>[coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...</td>\n",
       "      <td>2015-07-18T05:30:01Z</td>\n",
       "      <td>171174</td>\n",
       "      <td>594</td>\n",
       "      <td>35</td>\n",
       "      <td>148.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:18.180173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>uFRn2Jg1vbk</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>COFFEE YOGA EP2. ç§å½±ç‘œçˆ (ğ¡ƒæ¨¡MODELSå¿…å­¸)</td>\n",
       "      <td>æƒ³æ“ºéšposeå½±ç›¸ï¼ŒSHOWSHOWéšèº«æï¼Ÿ\\nä»Šæ¬¡å°±æ•™å„ä½ç¾å¥³å€‘å…©æ‹›å‹•ä½œæ—èº«å•¦\\næƒ³å­¸æ›´å¤š...</td>\n",
       "      <td>[ç§å½±, ğ¡ƒæ¨¡, Yoga (Sport), Model (Profession), pos...</td>\n",
       "      <td>2015-07-10T12:32:18Z</td>\n",
       "      <td>67662</td>\n",
       "      <td>383</td>\n",
       "      <td>22</td>\n",
       "      <td>140.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:18.260663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>SCUXhKmOulc</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>COFFEE YOGA SPECIAL æŸ”è»Ÿå’–å•¡ X å‰›ç¡¬ç”·ä»”ï¼ˆç”·å¥³ç‘œçˆæ²™ç˜ç¯‡ï¼‰</td>\n",
       "      <td>ä»Šæ¬¡å»åˆ°æ²™ç˜é‡ä¸Šç¡¬å´©å´©å˜…ä¼ä»”\\næ–¼æ˜¯é‚€è«‹ä½¢åŒæˆ‘ä¸€é½Šåšç‘œçˆ\\nå¸Œæœ›å‘å¤§å®¶ç¤ºç¯„ç”·å¥³éƒ½å•±åšå˜…ç‘œçˆå‹•...</td>\n",
       "      <td>[COFFEE, Yoga (Sport), Hong Kong (Country), ç‘œçˆ...</td>\n",
       "      <td>2015-07-05T03:00:01Z</td>\n",
       "      <td>50866</td>\n",
       "      <td>345</td>\n",
       "      <td>36</td>\n",
       "      <td>205.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:18.260689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>iET9uY2luDQ</td>\n",
       "      <td>Coffeeæ—èŠŠå¦¤</td>\n",
       "      <td>COFFEE YOGA EP1. æ•™ä½ ç‘œçˆåŸºæœ¬ä¸‰å¼</td>\n",
       "      <td>ç‘œçˆåŸºæœ¬ä¸‰å¼ï¼Œä¸€æ•™ä½ å°±è­˜ï¼\\nCOFFEE æ—èŠŠå¦¤ youtube channel ç¬¬ä¸€æ¢ç‰‡...</td>\n",
       "      <td>[COFFEE, YOGA, æ—èŠŠå¦¤, ç‘œçˆ]</td>\n",
       "      <td>2015-07-04T09:00:01Z</td>\n",
       "      <td>96398</td>\n",
       "      <td>1029</td>\n",
       "      <td>52</td>\n",
       "      <td>221.0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>2023-04-16T09:42:18.260702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VideoId ChannelTitle  \\\n",
       "0    WxTxeyqRM4E    Coffeeæ—èŠŠå¦¤   \n",
       "1    ibZ6t_lTTIA    Coffeeæ—èŠŠå¦¤   \n",
       "2    1AqSRo535vs    Coffeeæ—èŠŠå¦¤   \n",
       "3    8ZLyuY01Dqo    Coffeeæ—èŠŠå¦¤   \n",
       "4    pmOdWGRcNvc    Coffeeæ—èŠŠå¦¤   \n",
       "..           ...          ...   \n",
       "348  11tdiQZb-BM    Coffeeæ—èŠŠå¦¤   \n",
       "349  SUy3-htFkys    Coffeeæ—èŠŠå¦¤   \n",
       "350  uFRn2Jg1vbk    Coffeeæ—èŠŠå¦¤   \n",
       "351  SCUXhKmOulc    Coffeeæ—èŠŠå¦¤   \n",
       "352  iET9uY2luDQ    Coffeeæ—èŠŠå¦¤   \n",
       "\n",
       "                                            VideoTitle  \\\n",
       "0    è¶ç€å…’ç«¥ç¯€åŒå¤§å®¶å®£ä½ˆCoffeeSweatä»£è¨€äººğŸŒŸé™³ä¼¯å€‹fdï½ç¿Ÿä¼¯ğŸ˜!! #coffeesw...   \n",
       "1             28åˆ†é˜ å¥³æ€§æ—¥å¸¸é¤Šç”Ÿç‘œä¼½ï½œç”±å…§åˆ°å¤–ä¿é¤Šï½œå…¨èº«ä¿å¥æ‹‰ç­‹â™¥ï¸æ„›è‡ªå·±â™¥ï¸ï½œå­•å©¦éƒ½èƒ½åš   \n",
       "2             22åˆ†é˜ æ¥µæœ‰æ•ˆå…¨èº«å±€éƒ¨è‚Œè‚‰è¨“ç·´ï½œç”¨body weightå¢è‚Œï½œ14å¤©è‚ŒåŠ›æŒ‘æˆ°ğŸ”¥   \n",
       "3                                      æ¯å¤©éƒ½è¦ç©¿ç€è…°å°å»ç‚ºè…°éƒ¨å¡‘å½¢ğŸ”¥   \n",
       "4                 CoffeeSweat 2023 Spring Collectionâ™¥ï¸   \n",
       "..                                                 ...   \n",
       "348                     COFFEE YOGA EP4. å‡CUPç‘œçˆï¼å¹«ä½ æ¸›è‚šè…©ï¼   \n",
       "349                           COFFEE YOGA EP3. ç‘œçˆç”·å¥³å¤§ä¸åŒ   \n",
       "350                 COFFEE YOGA EP2. ç§å½±ç‘œçˆ (ğ¡ƒæ¨¡MODELSå¿…å­¸)   \n",
       "351           COFFEE YOGA SPECIAL æŸ”è»Ÿå’–å•¡ X å‰›ç¡¬ç”·ä»”ï¼ˆç”·å¥³ç‘œçˆæ²™ç˜ç¯‡ï¼‰   \n",
       "352                          COFFEE YOGA EP1. æ•™ä½ ç‘œçˆåŸºæœ¬ä¸‰å¼   \n",
       "\n",
       "                                           Description  \\\n",
       "0                                                        \n",
       "1    On coffee lam\\nWrap around long sleeve- white\\...   \n",
       "2    On Coffee Lam\\nChic Sports Braï¼ˆMercury Greyï¼‰\\n...   \n",
       "3                                                        \n",
       "4                                  www.CoffeeSweat.com   \n",
       "..                                                 ...   \n",
       "348  ä¸€é€£å…©é›†å‡ç´šç‘œçˆç¯‡ï¼Œç¬¬ä¸€é›†å…ˆæ•™å¤§å®¶æ¸›ï¼è‚šï¼è…© ï¼å…ˆæœ‰å…©å€‹å‹•ä½œæ”¹å–„å¯’èƒŒå•é¡Œï¼Œå†åŠ å…©å€‹å‹•ä½œåŒå¹«ä½ ...   \n",
       "349  ç”·ä»”å¥³ä»”åšç‘œçˆå‹•ä½œå„æœ‰å„å›°é›£ï¼Œä»Šæ¬¡å°±åŒå¤§å®¶ç°¡å–®ç¤ºç¯„ä¸‹å•¦ï¼\\næƒ³å­¸æ›´å¤šï¼Œè¨˜å¾—SUBSCRIBE...   \n",
       "350  æƒ³æ“ºéšposeå½±ç›¸ï¼ŒSHOWSHOWéšèº«æï¼Ÿ\\nä»Šæ¬¡å°±æ•™å„ä½ç¾å¥³å€‘å…©æ‹›å‹•ä½œæ—èº«å•¦\\næƒ³å­¸æ›´å¤š...   \n",
       "351  ä»Šæ¬¡å»åˆ°æ²™ç˜é‡ä¸Šç¡¬å´©å´©å˜…ä¼ä»”\\næ–¼æ˜¯é‚€è«‹ä½¢åŒæˆ‘ä¸€é½Šåšç‘œçˆ\\nå¸Œæœ›å‘å¤§å®¶ç¤ºç¯„ç”·å¥³éƒ½å•±åšå˜…ç‘œçˆå‹•...   \n",
       "352  ç‘œçˆåŸºæœ¬ä¸‰å¼ï¼Œä¸€æ•™ä½ å°±è­˜ï¼\\nCOFFEE æ—èŠŠå¦¤ youtube channel ç¬¬ä¸€æ¢ç‰‡...   \n",
       "\n",
       "                                                  Tags        Published_date  \\\n",
       "0                                                 None  2023-04-04T09:18:00Z   \n",
       "1    [coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...  2023-04-01T07:50:53Z   \n",
       "2    [coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...  2023-03-20T04:51:15Z   \n",
       "3                                                 None  2023-03-18T04:44:13Z   \n",
       "4                                                 None  2023-03-13T08:52:26Z   \n",
       "..                                                 ...                   ...   \n",
       "348  [coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...  2015-07-26T03:08:00Z   \n",
       "349  [coffee, coffee lam, coffeelam, æ—èŠŠå¦¤, coffeeyog...  2015-07-18T05:30:01Z   \n",
       "350  [ç§å½±, ğ¡ƒæ¨¡, Yoga (Sport), Model (Profession), pos...  2015-07-10T12:32:18Z   \n",
       "351  [COFFEE, Yoga (Sport), Hong Kong (Country), ç‘œçˆ...  2015-07-05T03:00:01Z   \n",
       "352                            [COFFEE, YOGA, æ—èŠŠå¦¤, ç‘œçˆ]  2015-07-04T09:00:01Z   \n",
       "\n",
       "      Views  Likes  Comments  Duration Definition Caption  \\\n",
       "0     10622    207         5      13.0         hd   false   \n",
       "1     55057   1937       123    1762.0         hd   false   \n",
       "2     95416   2072       156    1470.0         hd   false   \n",
       "3     15493    206         7      17.0         hd   false   \n",
       "4      8326    231         5      61.0         hd   false   \n",
       "..      ...    ...       ...       ...        ...     ...   \n",
       "348  146074   1330        33     200.0         hd   false   \n",
       "349  171174    594        35     148.0         hd   false   \n",
       "350   67662    383        22     140.0         hd   false   \n",
       "351   50866    345        36     205.0         hd   false   \n",
       "352   96398   1029        52     221.0         hd   false   \n",
       "\n",
       "                DataRetrievedAt  \n",
       "0    2023-04-16T09:42:16.977984  \n",
       "1    2023-04-16T09:42:16.978017  \n",
       "2    2023-04-16T09:42:16.978034  \n",
       "3    2023-04-16T09:42:16.978050  \n",
       "4    2023-04-16T09:42:16.978065  \n",
       "..                          ...  \n",
       "348  2023-04-16T09:42:18.180162  \n",
       "349  2023-04-16T09:42:18.180173  \n",
       "350  2023-04-16T09:42:18.260663  \n",
       "351  2023-04-16T09:42:18.260689  \n",
       "352  2023-04-16T09:42:18.260702  \n",
       "\n",
       "[353 rows x 13 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_details_result = get_video_details(youtube, video_ids)\n",
    "pd.DataFrame(get_video_details_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f1425974eb0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.allvideodetails.insert_many(get_video_details_result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove duplicate video details in the sentiment collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is to remove video details in the sentiment collection\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['youtubedataapi0412']\n",
    "collection = db['allcomments_sample_sentiment_0414']\n",
    "\n",
    "# Get a list of unique comments in the collection\n",
    "unique_comments = collection.distinct('Comment')\n",
    "\n",
    "# Iterate through the collection and remove any documents with duplicate comments\n",
    "for comment in unique_comments:\n",
    "    # Count the number of documents with this comment\n",
    "    count = collection.count_documents({'Comment': comment})\n",
    "\n",
    "    # If there is more than one document, delete all but one\n",
    "    if count > 1:\n",
    "        # Get all documents with this comment\n",
    "        documents = collection.find({'Comment': comment})\n",
    "\n",
    "        # Keep the first document and delete the rest\n",
    "        first_document = True\n",
    "        for document in documents:\n",
    "            if first_document:\n",
    "                first_document = False\n",
    "            else:\n",
    "                collection.delete_one({'_id': document['_id']})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get video comments from video ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=NJZ95sZlXL4&maxResults=100&key=AIzaSyColQwCiZxVE9zGJEcZ54SjVCT0tcqY1xE&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\">\n",
      "Could not get comments for video NJZ95sZlXL4\n"
     ]
    }
   ],
   "source": [
    "all_comments_in_videos = get_comments_in_videos(youtube, video_ids)\n",
    "# pd.DataFrame(all_comments_in_videos[1])  # disabled comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>commentText</th>\n",
       "      <th>commentPublishedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>DataRetrievedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pgGoBihIUiU</td>\n",
       "      <td>[Do you have exercise for foot sprain?, thanks...</td>\n",
       "      <td>[2023-04-15T09:53:26Z, 2023-04-15T09:37:06Z, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2023-04-15T11:16:34.802343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G0cBlx-Jfdo</td>\n",
       "      <td>[Thank you emi. â¤, Recipe for the banana cake ...</td>\n",
       "      <td>[2023-04-14T00:01:09Z, 2023-04-12T01:12:11Z, 2...</td>\n",
       "      <td>[0, 1, 0, 5, 3, 3, 3, 7, 4, 3, 3, 4]</td>\n",
       "      <td>2023-04-15T11:16:35.048075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6sLXvyL-JEc</td>\n",
       "      <td>[this vlog was filmed more than a year agoğŸ˜³ so...</td>\n",
       "      <td>[2023-04-09T12:52:58Z, 2023-04-14T05:19:00Z, 2...</td>\n",
       "      <td>[56, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>2023-04-15T11:16:35.342696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D8V_No7wxVQ</td>\n",
       "      <td>[Fun video! Thanks for sharing ğŸ‘Œ, in this peri...</td>\n",
       "      <td>[2023-04-12T16:22:46Z, 2023-04-08T15:42:04Z, 2...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 6, ...</td>\n",
       "      <td>2023-04-15T11:16:36.038890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MJapk3ZX5SE</td>\n",
       "      <td>[good job emi wong youre spanish sounds pretty...</td>\n",
       "      <td>[2023-04-08T15:47:21Z, 2023-04-06T09:34:54Z, 2...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 6, 1, 0, 0, 2, 1, 6, 1, 0, 16,...</td>\n",
       "      <td>2023-04-15T11:16:36.294262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>WwqYFnBGjT8</td>\n",
       "      <td>[I also post what I eat everyday on my instagr...</td>\n",
       "      <td>[2019-07-16T10:24:46Z, 2022-07-02T04:45:57Z, 2...</td>\n",
       "      <td>[14, 0, 1, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 6,...</td>\n",
       "      <td>2023-04-15T11:19:37.889696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>DZ6voLaG9_I</td>\n",
       "      <td>[I also post what I eat everyday on my instagr...</td>\n",
       "      <td>[2019-07-16T08:54:18Z, 2023-03-09T13:32:52Z, 2...</td>\n",
       "      <td>[255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0...</td>\n",
       "      <td>2023-04-15T11:19:38.265562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Fo470c993yA</td>\n",
       "      <td>[I also post what I eat everyday on my instagr...</td>\n",
       "      <td>[2019-07-16T10:18:01Z, 2022-03-10T12:28:13Z, 2...</td>\n",
       "      <td>[18, 0, 0, 0, 3, 3, 0, 0, 5, 6, 1, 0, 1, 0, 5,...</td>\n",
       "      <td>2023-04-15T11:19:38.661458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>p1DJhMy0yCs</td>\n",
       "      <td>[I also post what I eat everyday on my instagr...</td>\n",
       "      <td>[2019-07-16T09:54:35Z, 2023-04-09T15:09:19Z, 2...</td>\n",
       "      <td>[87, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 0, 3, 0, 1,...</td>\n",
       "      <td>2023-04-15T11:19:39.284293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>zuXFRfbTmiU</td>\n",
       "      <td>[I also post what I eat everyday on my instagr...</td>\n",
       "      <td>[2019-07-16T10:04:25Z, 2023-03-16T20:19:18Z, 2...</td>\n",
       "      <td>[251, 0, 0, 0, 2, 0, 6, 1, 0, 0, 0, 3, 2, 0, 0...</td>\n",
       "      <td>2023-04-15T11:19:39.753356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         videoId                                        commentText  \\\n",
       "0    pgGoBihIUiU  [Do you have exercise for foot sprain?, thanks...   \n",
       "1    G0cBlx-Jfdo  [Thank you emi. â¤, Recipe for the banana cake ...   \n",
       "2    6sLXvyL-JEc  [this vlog was filmed more than a year agoğŸ˜³ so...   \n",
       "3    D8V_No7wxVQ  [Fun video! Thanks for sharing ğŸ‘Œ, in this peri...   \n",
       "4    MJapk3ZX5SE  [good job emi wong youre spanish sounds pretty...   \n",
       "..           ...                                                ...   \n",
       "437  WwqYFnBGjT8  [I also post what I eat everyday on my instagr...   \n",
       "438  DZ6voLaG9_I  [I also post what I eat everyday on my instagr...   \n",
       "439  Fo470c993yA  [I also post what I eat everyday on my instagr...   \n",
       "440  p1DJhMy0yCs  [I also post what I eat everyday on my instagr...   \n",
       "441  zuXFRfbTmiU  [I also post what I eat everyday on my instagr...   \n",
       "\n",
       "                                    commentPublishedAt  \\\n",
       "0    [2023-04-15T09:53:26Z, 2023-04-15T09:37:06Z, 2...   \n",
       "1    [2023-04-14T00:01:09Z, 2023-04-12T01:12:11Z, 2...   \n",
       "2    [2023-04-09T12:52:58Z, 2023-04-14T05:19:00Z, 2...   \n",
       "3    [2023-04-12T16:22:46Z, 2023-04-08T15:42:04Z, 2...   \n",
       "4    [2023-04-08T15:47:21Z, 2023-04-06T09:34:54Z, 2...   \n",
       "..                                                 ...   \n",
       "437  [2019-07-16T10:24:46Z, 2022-07-02T04:45:57Z, 2...   \n",
       "438  [2019-07-16T08:54:18Z, 2023-03-09T13:32:52Z, 2...   \n",
       "439  [2019-07-16T10:18:01Z, 2022-03-10T12:28:13Z, 2...   \n",
       "440  [2019-07-16T09:54:35Z, 2023-04-09T15:09:19Z, 2...   \n",
       "441  [2019-07-16T10:04:25Z, 2023-03-16T20:19:18Z, 2...   \n",
       "\n",
       "                                             likeCount  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1                 [0, 1, 0, 5, 3, 3, 3, 7, 4, 3, 3, 4]   \n",
       "2    [56, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3    [0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 6, ...   \n",
       "4    [1, 1, 0, 1, 0, 6, 1, 0, 0, 2, 1, 6, 1, 0, 16,...   \n",
       "..                                                 ...   \n",
       "437  [14, 0, 1, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 6,...   \n",
       "438  [255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0...   \n",
       "439  [18, 0, 0, 0, 3, 3, 0, 0, 5, 6, 1, 0, 1, 0, 5,...   \n",
       "440  [87, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 0, 3, 0, 1,...   \n",
       "441  [251, 0, 0, 0, 2, 0, 6, 1, 0, 0, 0, 3, 2, 0, 0...   \n",
       "\n",
       "                DataRetrievedAt  \n",
       "0    2023-04-15T11:16:34.802343  \n",
       "1    2023-04-15T11:16:35.048075  \n",
       "2    2023-04-15T11:16:35.342696  \n",
       "3    2023-04-15T11:16:36.038890  \n",
       "4    2023-04-15T11:16:36.294262  \n",
       "..                          ...  \n",
       "437  2023-04-15T11:19:37.889696  \n",
       "438  2023-04-15T11:19:38.265562  \n",
       "439  2023-04-15T11:19:38.661458  \n",
       "440  2023-04-15T11:19:39.284293  \n",
       "441  2023-04-15T11:19:39.753356  \n",
       "\n",
       "[442 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_comments_in_videos[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f8a24c816f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.allcommentsinfo2.insert_many(all_comments_in_videos[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unwind comments collected in mongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0x7f8a24cc3f40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unwind the arrays inside all comments info document\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "# access the database\n",
    "db = client['youtubedataapi0415']\n",
    "\n",
    "# access the collection\n",
    "collection = db['allcommentsinfo2']\n",
    "\n",
    "# aggregation pipeline\n",
    "pipeline = [\n",
    "    {\n",
    "        '$unwind': {\n",
    "            'path': '$commentText',\n",
    "            'includeArrayIndex': 'arrayIndex'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'videoId': 1,\n",
    "            'commentText': 1,\n",
    "            'commentPublishedAt': {'$arrayElemAt': ['$commentPublishedAt', '$arrayIndex']},\n",
    "            'likeCount': {'$arrayElemAt': ['$likeCount', '$arrayIndex']},\n",
    "            'DataRetrievedAt': 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$out': 'allcommentsinfo_unwinded2'\n",
    "    }\n",
    "]\n",
    "\n",
    "# execute aggregation pipeline\n",
    "collection.aggregate(pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating small size test samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObjectId('64366db41663f97dab7cf6a2'), ObjectId('64366db41663f97dab7cf6a3'), ObjectId('64366db41663f97dab7cf6a4'), ObjectId('64366db41663f97dab7cf6a5'), ObjectId('64366db41663f97dab7cf6a6')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0x7f00d1b7bd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# get the first 5 documents in allcommentsinfo for testing\n",
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient('mongodb://localhost:27017/')\n",
    "db = client['youtubedataapi0412']\n",
    "\n",
    "# Select the first 10 documents in the collection\n",
    "pipeline = [\n",
    "    {'$limit': 5},\n",
    "]\n",
    "\n",
    "cursor = db['allcommentsinfo'].aggregate(pipeline)\n",
    "\n",
    "# Insert the selected documents into a new collection\n",
    "new_collection = db['allcommentsinfo_sample2']\n",
    "result = new_collection.insert_many(list(cursor))\n",
    "\n",
    "print(result.inserted_ids)\n",
    "\n",
    "# aggregation pipeline\n",
    "pipeline = [\n",
    "    {\n",
    "        '$unwind': {\n",
    "            'path': '$commentText',\n",
    "            'includeArrayIndex': 'arrayIndex'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'videoId': 1,\n",
    "            'commentText': 1,\n",
    "            'commentPublishedAt': {'$arrayElemAt': ['$commentPublishedAt', '$arrayIndex']},\n",
    "            'likeCount': {'$arrayElemAt': ['$likeCount', '$arrayIndex']},\n",
    "            'DataRetrievedAt': 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$out': 'allcommentsinfo_aggregated_sample2'\n",
    "    }\n",
    "]\n",
    "\n",
    "# execute aggregation pipeline\n",
    "new_collection.aggregate(pipeline)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Cloud Natural Language Sentiment Analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get sentiment analysis scores from comments collected in mongoDB using Google Cloud Natural Language API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import language_v1\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['youtubedataapi0415']\n",
    "collection = db['allcommentsinfo_unwinded2']\n",
    "\n",
    "# Set up Google Cloud Natural Language API client\n",
    "client = language_v1.LanguageServiceClient()\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open('sentiment0415emi.csv', mode='w', newline='') as sentiment_file:\n",
    "    sentiment_writer = csv.writer(sentiment_file)\n",
    "    sentiment_writer.writerow(\n",
    "        ['Comment', 'Language', 'LikeCount', 'CommentPublishedTime', 'Score', 'Magnitude'])\n",
    "\n",
    "    # Create a new collection for sentiment analysis results\n",
    "    sentiment_collection = db['allcommentsinfo_unwinded_sentiment2']\n",
    "\n",
    "    # Iterate over documents in collection\n",
    "    for document in collection.find():\n",
    "        # Extract commentText array\n",
    "        comment = document['commentText']\n",
    "        likecount = document['likeCount']\n",
    "        commentpublishedtime = document['commentPublishedAt']\n",
    "        # videoId = document['videoId'] (0415 no videoId)\n",
    "\n",
    "        # Check if the comment has already been analyzed\n",
    "        existing_result = sentiment_collection.find_one({'Comment': comment})\n",
    "        if existing_result:\n",
    "            print(f\"Comment '{comment}' already analyzed\")\n",
    "\n",
    "        try:\n",
    "            # Call the analyze_sentiment method to detect the language and analyze the sentiment\n",
    "            document = language_v1.Document(\n",
    "                content=comment, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "            response = client.analyze_sentiment(\n",
    "                request={'document': document, 'encoding_type': language_v1.EncodingType.UTF8})\n",
    "\n",
    "            # Extract language and sentiment\n",
    "            language = response.language\n",
    "            sentiment = response.document_sentiment\n",
    "\n",
    "            # Write result to CSV file\n",
    "            sentiment_writer.writerow(\n",
    "                [comment, language, likecount, commentpublishedtime, sentiment.score, sentiment.magnitude])\n",
    "\n",
    "            # Save result to MongoDB collection\n",
    "            # add videoId from allcommentsinfo unwinded collection\n",
    "            sentiment_collection.insert_one({\n",
    "                'Comment': comment,\n",
    "                'Language': language,\n",
    "                'LikeCount': likecount,\n",
    "                'CommentPublishedTime': commentpublishedtime,\n",
    "                'Score': sentiment.score,\n",
    "                'Magnitude': sentiment.magnitude\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # Skip unsupported language comments\n",
    "            if 'is not supported for document_sentiment analysis' in str(e):\n",
    "                print(\n",
    "                    f\"Skipping comment '{comment}' due to unsupported language\")\n",
    "                continue\n",
    "\n",
    "            # Handle other exceptions\n",
    "            print(f\"Error processing comment '{comment}': {e}\")\n",
    "\n",
    "        # Add a 0.05-second delay between each analysis to avoid hitting the rate limit\n",
    "        time.sleep(0.05)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check and Remove duplicate comments in the sentiment collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is to remove duplicate comments in the sentiment collection\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['youtubedataapi0412']\n",
    "collection = db['allcomments_sample_sentiment_0414']\n",
    "\n",
    "# Get a list of unique comments in the collection\n",
    "unique_comments = collection.distinct('Comment')\n",
    "\n",
    "# Iterate through the collection and remove any documents with duplicate comments\n",
    "for comment in unique_comments:\n",
    "    # Count the number of documents with this comment\n",
    "    count = collection.count_documents({'Comment': comment})\n",
    "\n",
    "    # If there is more than one document, delete all but one\n",
    "    if count > 1:\n",
    "        # Get all documents with this comment\n",
    "        documents = collection.find({'Comment': comment})\n",
    "\n",
    "        # Keep the first document and delete the rest\n",
    "        first_document = True\n",
    "        for document in documents:\n",
    "            if first_document:\n",
    "                first_document = False\n",
    "            else:\n",
    "                collection.delete_one({'_id': document['_id']})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "print(findspark.init())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/patty/.local/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/patty/.ivy2/cache\n",
      "The jars for the packages stored in: /home/patty/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      "com.google.cloud.spark#spark-3.1-bigquery added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-360b06ed-8585-4a75-8844-128a45b1ce10;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.0 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.375 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;2.4.4 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound org.postgresql#postgresql;42.2.18 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "\tfound com.google.cloud.spark#spark-3.1-bigquery;0.30.0 in central\n",
      "\tfound com.google.cloud.spark#spark-bigquery-dsv2-common;0.30.0 in central\n",
      "\tfound com.google.cloud.spark#spark-bigquery-connector-common;0.30.0 in central\n",
      "\tfound com.google.cloud.spark#bigquery-connector-common;0.30.0 in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-bigquerystorage-v1;2.34.2 in central\n",
      "\tfound io.grpc#grpc-api;1.54.0 in central\n",
      "\tfound io.grpc#grpc-context;1.54.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.54.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.54.0 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.15.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.54.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.22.2 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-bigquerystorage-v1;2.34.2 in central\n",
      "\tfound com.google.api#api-common;2.7.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound org.checkerframework#checker-qual;3.32.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.cloud#google-cloud-bigquery;2.24.4 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.14.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.22.2 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.10.0 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.14.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.1 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.1 in central\n",
      "\tfound com.google.api#gax-httpjson;0.109.0 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.1 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.14 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.16 in central\n",
      "\tfound org.checkerframework#checker-compat-qual;2.5.5 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.apis#google-api-services-bigquery;v2-rev20230318-2.0.0 in central\n",
      "\tfound com.google.api#gax;2.24.0 in central\n",
      "\tfound org.threeten#threetenbp;1.6.7 in central\n",
      "\tfound org.threeten#threeten-extra;1.7.2 in central\n",
      "\tfound com.google.cloud#google-cloud-bigquerystorage;2.34.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.24.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.54.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.54.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.54.0 in central\n",
      "\tfound org.json#json;20230227 in central\n",
      "\tfound io.grpc#grpc-core;1.54.0 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.54.0 in central\n",
      "\tfound org.apache.arrow#arrow-vector;11.0.0 in central\n",
      "\tfound org.apache.arrow#arrow-format;11.0.0 in central\n",
      "\tfound com.google.flatbuffers#flatbuffers-java;1.12.0 in central\n",
      "\tfound org.apache.arrow#arrow-memory-core;11.0.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.14.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.14.2 in central\n",
      "\tfound com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.14.2 in central\n",
      "\tfound io.netty#netty-common;4.1.90.Final in central\n",
      "\tfound com.google.inject#guice;5.1.0 in central\n",
      "\tfound javax.inject#javax.inject;1 in central\n",
      "\tfound aopalliance#aopalliance;1.0 in central\n",
      "\tfound io.grpc#grpc-netty;1.54.0 in central\n",
      "\tfound io.netty#netty-codec-http2;4.1.90.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.90.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.90.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.90.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.90.Final in central\n",
      "\tfound io.netty#netty-handler;4.1.90.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.90.Final in central\n",
      "\tfound io.netty#netty-codec-http;4.1.90.Final in central\n",
      "\tfound io.netty#netty-tcnative-boringssl-static;2.0.59.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.59.Final in central\n",
      "\tfound org.apache.arrow#arrow-memory-netty;11.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.9.1 in central\n",
      "\tfound org.apache.beam#beam-sdks-java-io-hadoop-common;2.43.0 in central\n",
      "\tfound org.apache.arrow#arrow-compression;11.0.0 in central\n",
      "\tfound org.apache.commons#commons-compress;1.22 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.9-1 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.54.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.23 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound io.netty#netty-handler-proxy;4.1.90.Final in central\n",
      "\tfound io.netty#netty-codec-socks;4.1.90.Final in central\n",
      ":: resolution report :: resolve 3467ms :: artifacts dl 74ms\n",
      "\t:: modules in use:\n",
      "\taopalliance#aopalliance;1.0 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.375 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.14.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.14.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.14.2 from central in [default]\n",
      "\tcom.github.luben#zstd-jni;1.4.9-1 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.7.0 from central in [default]\n",
      "\tcom.google.api#gax;2.24.0 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.24.0 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.109.0 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-bigquerystorage-v1;2.34.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-bigquerystorage-v1;2.34.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.15.0 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.10.0 from central in [default]\n",
      "\tcom.google.apis#google-api-services-bigquery;v2-rev20230318-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-bigquery;2.24.4 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-bigquerystorage;2.34.2 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.14.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.14.0 from central in [default]\n",
      "\tcom.google.cloud.spark#bigquery-connector-common;0.30.0 from central in [default]\n",
      "\tcom.google.cloud.spark#spark-3.1-bigquery;0.30.0 from central in [default]\n",
      "\tcom.google.cloud.spark#spark-bigquery-connector-common;0.30.0 from central in [default]\n",
      "\tcom.google.cloud.spark#spark-bigquery-dsv2-common;0.30.0 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.9.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.flatbuffers#flatbuffers-java;1.12.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.1 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.1 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.1 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.1 from central in [default]\n",
      "\tcom.google.inject#guice;5.1.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.22.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.22.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-netty;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.54.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.54.0 from central in [default]\n",
      "\tio.netty#netty-buffer;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-codec-http;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-codec-http2;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-codec-socks;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-handler-proxy;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-boringssl-static;2.0.59.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.59.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.90.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.90.Final from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjavax.inject#javax.inject;1 from central in [default]\n",
      "\torg.apache.arrow#arrow-compression;11.0.0 from central in [default]\n",
      "\torg.apache.arrow#arrow-format;11.0.0 from central in [default]\n",
      "\torg.apache.arrow#arrow-memory-core;11.0.0 from central in [default]\n",
      "\torg.apache.arrow#arrow-memory-netty;11.0.0 from central in [default]\n",
      "\torg.apache.arrow#arrow-vector;11.0.0 from central in [default]\n",
      "\torg.apache.beam#beam-sdks-java-io-hadoop-common;2.43.0 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.22 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.0 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.14 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.16 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;2.4.4 from central in [default]\n",
      "\torg.checkerframework#checker-compat-qual;2.5.5 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.32.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.23 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.json#json;20230227 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\torg.postgresql#postgresql;42.2.18 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.threeten#threeten-extra;1.7.2 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.7 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.checkerframework#checker-qual;3.5.0 by [org.checkerframework#checker-qual;3.32.0] in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 by [com.google.code.gson#gson;2.9.1] in [default]\n",
      "\torg.checkerframework#checker-qual;3.10.0 by [org.checkerframework#checker-qual;3.32.0] in [default]\n",
      "\torg.checkerframework#checker-qual;3.12.0 by [org.checkerframework#checker-qual;3.32.0] in [default]\n",
      "\tcom.google.code.gson#gson;2.9.0 by [com.google.code.gson#gson;2.9.1] in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.21 by [org.codehaus.mojo#animal-sniffer-annotations;1.23] in [default]\n",
      "\tio.perfmark#perfmark-api;0.25.0 by [io.perfmark#perfmark-api;0.26.0] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  110  |   0   |   0   |   7   ||  103  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-360b06ed-8585-4a75-8844-128a45b1ce10\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 103 already retrieved (0kB/31ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 03:57:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "packages = [\n",
    "    \"org.apache.hadoop:hadoop-aws:3.2.0\",\n",
    "    \"org.apache.spark:spark-avro_2.12:2.4.4\",\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    \"org.postgresql:postgresql:42.2.18\",\n",
    "    \"com.google.cloud.spark:spark-3.1-bigquery:0.30.0\"\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Transform youtube video data\")\\\n",
    "    .master('spark://localhost:7077')\\\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages))\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from mongoDB to spark\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write dataframe of top5hkchannelsinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ChannelTitle: string (nullable = true)\n",
      " |-- DataRetrievedAt: string (nullable = true)\n",
      " |-- channelId: string (nullable = true)\n",
      " |-- channelPublishedAt: string (nullable = true)\n",
      " |-- playlistId: string (nullable = true)\n",
      " |-- subscribers: integer (nullable = true)\n",
      " |-- totalVideos: integer (nullable = true)\n",
      " |-- totalViews: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+--------------------+-----------+-----------+----------+\n",
      "| ChannelTitle|     DataRetrievedAt|           channelId|  channelPublishedAt|          playlistId|subscribers|totalVideos|totalViews|\n",
      "+-------------+--------------------+--------------------+--------------------+--------------------+-----------+-----------+----------+\n",
      "|       ç¬‘æ³¢å­|2023-04-16T09:38:...|UCDpK1rg5I9Zc3ToY...|2006-09-09T19:59:59Z|UUDpK1rg5I9Zc3ToY...|     936000|       4354|1051897493|\n",
      "|        JASON|2023-04-16T09:38:...|UC4nsi0oM9WBNFv1R...|2013-06-16T13:50:59Z|UU4nsi0oM9WBNFv1R...|    1040000|       2955| 521248369|\n",
      "|é» Cook Guide|2023-04-16T09:38:...|UCXnWjmQ8BDE0sDIe...|2014-02-07T15:44:04Z|UUXnWjmQ8BDE0sDIe...|    1110000|       1356| 202603292|\n",
      "|     emi wong|2023-04-16T09:38:...|UCvGEK5_U-kLgO6-A...|2014-11-02T14:43:34Z|UUvGEK5_U-kLgO6-A...|    5960000|        442| 787128269|\n",
      "| Coffeeæ—èŠŠå¦¤|2023-04-16T09:38:...|UCxCZqbizSsnntlz6...|2015-06-02T07:09:15Z|UUxCZqbizSsnntlz6...|    1700000|        353| 261803319|\n",
      "+-------------+--------------------+--------------------+--------------------+--------------------+-----------+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top5hkchannelsinfo_0415 = spark.read.format('mongo').option(\n",
    "    'spark.mongodb.input.uri', 'mongodb://172.1.0.10/youtubedataapi0416.top5hkchannelsinfo').load()\n",
    "df_top5hkchannelsinfo_0415 = df_top5hkchannelsinfo_0415.drop('_id')\n",
    "df_top5hkchannelsinfo_0415.dtypes\n",
    "df_top5hkchannelsinfo_0415.printSchema()\n",
    "df_top5hkchannelsinfo_0415.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write dataframe of allvideodetails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- Caption: string (nullable = true)\n",
      " |-- ChannelTitle: string (nullable = true)\n",
      " |-- Comments: integer (nullable = true)\n",
      " |-- DataRetrievedAt: string (nullable = true)\n",
      " |-- Definition: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Duration: double (nullable = true)\n",
      " |-- Likes: integer (nullable = true)\n",
      " |-- Published_date: string (nullable = true)\n",
      " |-- Tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- VideoId: string (nullable = true)\n",
      " |-- VideoTitle: string (nullable = true)\n",
      " |-- Views: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------+------------+--------+--------------------+----------+-------------------------------------+--------+-----+--------------------+-------------------------+-----------+-----------------------------------+------+\n",
      "|year|month|day|hour|  weekday|Caption|ChannelTitle|Comments|     DataRetrievedAt|Definition|                          Description|Duration|Likes|      Published_date|                     Tags|    VideoId|                         VideoTitle| Views|\n",
      "+----+-----+---+----+---------+-------+------------+--------+--------------------+----------+-------------------------------------+--------+-----+--------------------+-------------------------+-----------+-----------------------------------+------+\n",
      "|2023|    4| 15|   9| Saturday|   true|      ç¬‘æ³¢å­|      90|2023-04-16T09:38:...|        hd|    ç„¡äººèƒ½æŠ—æ‹’é€™éº¼å¯æ„›çš„è‚‰æ¡‚ç‹—CafÃ©...|   566.0| 1342|2023-04-15T09:06:10Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|yOwSdw2Ep60|     ã€ğŸ˜è‚‰æ¡‚ç‹—ä¸»é¡ŒCafÃ© ã€‘æŠŠè‚‰æ¡‚...| 33366|\n",
      "|2023|    4| 15|   3| Saturday|  false|      ç¬‘æ³¢å­|      65|2023-04-16T09:38:...|        hd|  ç‚ºäº†æ—å©†å©†ğŸ˜³è”¬èœæ­Œå”±çµ„åˆæˆç«‹å•¦ï¼...|    45.0|  988|2023-04-15T03:21:58Z|                     null|XyWlV_5wE6U|  æ—å©†å©†æ²’æœ‰éŒ¯ğŸ‘µğŸ»ï¼ç”Ÿèœç™½èœæ˜¯æ­Œ...| 15467|\n",
      "|2023|    4| 14|   9|   Friday|   true|      ç¬‘æ³¢å­|      43|2023-04-16T09:38:...|        hd|      å¾æ—¥æœ¬äº¬éƒ½ğŸ‡¯ğŸ‡µè²·ä¾†çš„ç¾é£Ÿ\\næŠ¹...|   529.0|  985|2023-04-14T09:30:10Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|_Kacv5GlJxg|  ã€å¾æ—¥æœ¬äº¬éƒ½ğŸ‡¯ğŸ‡µè²·ä¾†çš„ç¾é£Ÿã€‘æŠ¹...| 27302|\n",
      "|2023|    4| 14|   9|   Friday|  false|      ç¬‘æ³¢å­|      36|2023-04-16T09:38:...|        hd|          å¤ªç©ºæ‰“åœ°é¼ ï¼Ÿæ‰“Imposter? ...|    23.0|  441|2023-04-14T09:01:39Z|                     null|e1WRjaYgKJE|       ç©éæœ€æƒ¡æçš„Among UsğŸ˜³ï¼Ÿï¼Ÿï¼Ÿ|  9052|\n",
      "|2023|    4| 13|  11| Thursday|   true|      ç¬‘æ³¢å­|      42|2023-04-16T09:38:...|        hd|  ğŸ˜›å¹¾å¹´å¾Œå†ä¾†é€™é–“å¤¾å¨ƒå¨ƒåº—ï¼å¼˜å¤§çš„...|   380.0| 1333|2023-04-13T11:01:15Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|EFXej9P6xk4| ã€ğŸ˜›éŸ“åœ‹å¤¾å¨ƒå¨ƒå¤©å ‚ã€‘ç–«æƒ…å¾Œå†ä¾†â€¦...| 49480|\n",
      "|2023|    4| 12|   9|Wednesday|  false|      ç¬‘æ³¢å­|      38|2023-04-16T09:38:...|        hd|           ç•¶Among Usè®ŠæˆçœŸäººåŒ–ğŸ˜ˆ?...|   631.0|  577|2023-04-12T09:00:34Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|o-lIiyrzy38|      Among UsçœŸäººåŒ–ï¼Ÿå®‡å®™ç‹¼äººæ®º...| 20068|\n",
      "|2023|    4| 11|  12|  Tuesday|   true|      ç¬‘æ³¢å­|      90|2023-04-16T09:38:...|        hd|å¦‚æœæˆ‘åœ¨é¦™æ¸¯ã€Œåšé€™ä»¶äº‹ã€ä¾¿çŠ¯æ³•äº†ï¼Ÿ...|   485.0| 2097|2023-04-11T12:18:12Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|SFSJEZcFLsM|     æˆ‘åšäº†ã€ŒğŸ˜²åœ¨é¦™æ¸¯çŠ¯æ³•ğŸˆ²ã€......|103896|\n",
      "|2023|    4| 11|  11|  Tuesday|  false|      ç¬‘æ³¢å­|      13|2023-04-16T09:38:...|        hd|               Doge simulator æŸ´ç‹—...|  7375.0|  407|2023-04-11T11:08:19Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|sn0m4w66ubE|     ã€ç‹—ç‹—ç‰ˆGTAğŸ¶ã€‘çˆ†ç¬‘æŸ´çŠ¬ğŸ¤£ç‚¸...| 15409|\n",
      "|2023|    4| 10|  10|   Monday|  false|      ç¬‘æ³¢å­|     146|2023-04-16T09:38:...|        hd|      æ˜ŸæœŸæ—¥å¥½å¤šå§å§è¡—ä¸Šè·³èˆğŸ’ƒ\\nğŸ˜³...|    60.0| 4142|2023-04-10T10:18:26Z|                     null|cc1BS62lZC0|ã€è¡—é ­æŒ‘æˆ°è·Ÿå§å§è·³èˆğŸ’ƒã€‘å®å®å™¹å™¹...| 67203|\n",
      "|2023|    4| 10|   9|   Monday|  false|      ç¬‘æ³¢å­|       6|2023-04-16T09:38:...|        hd|             åŠ ç­å°ä¸Š: https://www...| 17712.0|  287|2023-04-10T09:26:57Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|DIBlgkT-xPk|  ã€å¾©æ´»ç¯€åŠ ç­å°(ä¸‹)ã€‘ğŸ˜±ç›´æ’­åˆ°å¤©...| 12294|\n",
      "|2023|    4| 10|   7|   Monday|  false|      ç¬‘æ³¢å­|      66|2023-04-16T09:38:...|        hd|   å•ªå•ªå•ªä¹‹ç¥å†è‡¨ğŸ˜œ åˆå¯ä»¥æ—©åˆæ™šé£Ÿ...|   555.0| 1807|2023-04-10T07:41:39Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|nM-ZWw3e5cc|   ã€å¤¾å¨ƒå¨ƒã€‘ğŸ‡­ğŸ‡°é™å®šã€Œé¦™æ¸¯ä¹‹å…‰?...| 75475|\n",
      "|2023|    4|  9|  20|   Sunday|  false|      ç¬‘æ³¢å­|      14|2023-04-16T09:38:...|        hd|           é‡‘ä¸»DONATEğŸ‘‰ğŸ»(æœƒè‡ªå‹•è®€...| 15169.0|  362|2023-04-09T20:47:00Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|8shhIhsX3hg|    ã€éµé´¨æ®º!!!!ã€‘ğŸ˜³ç”Ÿçœ¼æŒ‘é‡éƒ½è¦...| 16111|\n",
      "|2023|    4|  8|   9| Saturday|   true|      ç¬‘æ³¢å­|     128|2023-04-16T09:38:...|        hd|  æ³¢å­ä¸€æ—¥åº—é•·ç³»åˆ—åˆä¾†å•¦ï¼\\nå¥½é–‹å¿ƒ...|   962.0| 2669|2023-04-08T09:00:00Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|-vvZF507BVE|       ã€ç¬‘æ³¢å­å†ãŠ™ï¸æ’ˆğŸ‘¨ğŸ»â€ğŸ’¼ã€‘ ...| 84002|\n",
      "|2023|    4|  7|  20|   Friday|  false|      ç¬‘æ³¢å­|      18|2023-04-16T09:38:...|        hd|           é‡‘ä¸»DONATEğŸ‘‰ğŸ»(æœƒè‡ªå‹•è®€...| 21367.0|  513|2023-04-07T20:08:06Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|0F3_re_Cno0|ã€å¾©æ´»ç¯€åŠ ç­å°ã€‘ğŸ˜†ä½ çŒœæˆ‘ç•«ã€Œå¾©æ´»...| 23161|\n",
      "|2023|    4|  7|   8|   Friday|   true|      ç¬‘æ³¢å­|     162|2023-04-16T09:38:...|        hd|    ç¬¬ä¸€å€‹é™¤ç½©å¾Œçš„æƒè¡—ï¼ (**æŒ‰è¨­å®š...|   994.0| 2864|2023-04-07T08:26:07Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|oVpnGKHy7qs|    ã€ğŸ˜›è‘µå»£ç¾é£Ÿæƒè¡—2023ã€‘é£Ÿç›¡æ–°...|135966|\n",
      "|2023|    4|  6|   8| Thursday|  false|      ç¬‘æ³¢å­|      74|2023-04-16T09:38:...|        hd|  é–‰åº—è£ä¿®ä¸€å€‹å¤šæœˆå¾ŒğŸ”æœ‰ä»€éº¼è®ŠåŒ–ï¼Ÿ...|   497.0| 1575|2023-04-06T08:54:04Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|myNf93uFPp4|     ã€å¤¾å¨ƒå¨ƒã€‘æœ—è±ªåŠNamcoé‡é–‹ğŸ¤©...| 69080|\n",
      "|2023|    4|  5|   8|Wednesday|  false|      ç¬‘æ³¢å­|      46|2023-04-16T09:38:...|        hd|            ç¬¨ç¬¨çš„æ­»æ³•DUMB WAYS TO...|   696.0| 1043|2023-04-05T08:51:52Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|_lI7y40LbFA|ã€ğŸ˜¨é˜»æ­¢æœ‹å‹è‡ªæ®ºçš„éŠæˆ²ï¼Ÿï¼ã€‘å¯æ˜¯...| 35960|\n",
      "|2023|    4|  4|   7|  Tuesday|  false|      ç¬‘æ³¢å­|      70|2023-04-16T09:38:...|        hd|   å®Œæˆ100è¬è¨‚é–±ç¬¨è±¬è·³ä¹‹å‰ï¼Œç¬¬ä¸€æ¬¡...|   639.0| 1450|2023-04-04T07:15:06Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|ExFuS-VSE0M|   ã€æ¥µé™æŒ‘æˆ°ğŸ”¥ã€‘æˆ‘åœ¨600ç±³é«˜å±±ä¸Š...| 45426|\n",
      "|2023|    4|  3|   8|   Monday|   true|      ç¬‘æ³¢å­|      85|2023-04-16T09:38:...|        hd|    å–®è‰²å¤¾å¨ƒå¨ƒæŒ‘æˆ°åˆä¾†å•¦ï¼ğŸŒˆ\\nå¤§å®¶...|   351.0| 1326|2023-04-03T08:31:31Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|KC45-mFfhyQ|   ã€å¤¾å¨ƒå¨ƒã€‘ ğŸ’›é¡è‰²æŒ‘æˆ°ğŸŒæŠŠæ‰€æœ‰...| 55034|\n",
      "|2023|    4|  2|  17|   Sunday|  false|      ç¬‘æ³¢å­|       5|2023-04-16T09:38:...|        hd|               Hardcore~XD ä»²ä¿‚Har...|  7350.0|  292|2023-04-02T17:06:27Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|H6qNZ6ZFxxI|             ã€Resident Evil 4æœ€...| 11872|\n",
      "+----+-----+---+----+---------+-------+------------+--------+--------------------+----------+-------------------------------------+--------+-----+--------------------+-------------------------+-----------+-----------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_allvideodetails0418 = spark.read.format('mongo').option(\n",
    "    'spark.mongodb.input.uri', 'mongodb://172.1.0.10/youtubedataapi0416.allvideodetails').load()\n",
    "\n",
    "df_allvideodetails0418.createOrReplaceTempView('df_allvideodetails0418')\n",
    "\n",
    "df_allvideodetails0418 = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(year from df_allvideodetails0418.Published_date) as year,\n",
    "        EXTRACT(month from df_allvideodetails0418.Published_date) as month,\n",
    "        EXTRACT(day from df_allvideodetails0418.Published_date) as day,\n",
    "        EXTRACT(hour from df_allvideodetails0418.Published_date) as hour,\n",
    "        date_format(df_allvideodetails0418.Published_date, 'EEEE') as weekday,\n",
    "        *\n",
    "    FROM df_allvideodetails0418\n",
    "\"\"\")\n",
    "df_allvideodetails0418 = df_allvideodetails0418.drop(\"_id\")\n",
    "df_allvideodetails0418.printSchema()\n",
    "df_allvideodetails0418.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calulating ratio of likes/comments/duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- Caption: string (nullable = true)\n",
      " |-- ChannelTitle: string (nullable = true)\n",
      " |-- Comments: integer (nullable = true)\n",
      " |-- DataRetrievedAt: string (nullable = true)\n",
      " |-- Definition: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Duration: double (nullable = true)\n",
      " |-- Likes: integer (nullable = true)\n",
      " |-- Published_date: string (nullable = true)\n",
      " |-- Tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- VideoId: string (nullable = true)\n",
      " |-- VideoTitle: string (nullable = true)\n",
      " |-- Views: integer (nullable = true)\n",
      " |-- TagNum: integer (nullable = false)\n",
      " |-- likeRatio: double (nullable = true)\n",
      " |-- commentRatio: double (nullable = true)\n",
      "\n",
      "+----+-----+---+----+---------+-------+------------+--------+--------------------+----------+-------------------------------------+--------+-----+--------------------+-------------------------+-----------+-----------------------------------+------+------+--------------------+--------------------+\n",
      "|year|month|day|hour|  weekday|Caption|ChannelTitle|Comments|     DataRetrievedAt|Definition|                          Description|Duration|Likes|      Published_date|                     Tags|    VideoId|                         VideoTitle| Views|TagNum|           likeRatio|        commentRatio|\n",
      "+----+-----+---+----+---------+-------+------------+--------+--------------------+----------+-------------------------------------+--------+-----+--------------------+-------------------------+-----------+-----------------------------------+------+------+--------------------+--------------------+\n",
      "|2023|    4| 15|   9| Saturday|   true|      ç¬‘æ³¢å­|      90|2023-04-16T09:38:...|        hd|    ç„¡äººèƒ½æŠ—æ‹’é€™éº¼å¯æ„›çš„è‚‰æ¡‚ç‹—CafÃ©...|   566.0| 1342|2023-04-15T09:06:10Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|yOwSdw2Ep60|     ã€ğŸ˜è‚‰æ¡‚ç‹—ä¸»é¡ŒCafÃ© ã€‘æŠŠè‚‰æ¡‚...| 33366|     7| 0.04022058382784871|0.002697356590541...|\n",
      "|2023|    4| 15|   3| Saturday|  false|      ç¬‘æ³¢å­|      65|2023-04-16T09:38:...|        hd|  ç‚ºäº†æ—å©†å©†ğŸ˜³è”¬èœæ­Œå”±çµ„åˆæˆç«‹å•¦ï¼...|    45.0|  988|2023-04-15T03:21:58Z|                       []|XyWlV_5wE6U|  æ—å©†å©†æ²’æœ‰éŒ¯ğŸ‘µğŸ»ï¼ç”Ÿèœç™½èœæ˜¯æ­Œ...| 15467|     0| 0.06387793366522274|0.004202495635869916|\n",
      "|2023|    4| 14|   9|   Friday|   true|      ç¬‘æ³¢å­|      43|2023-04-16T09:38:...|        hd|      å¾æ—¥æœ¬äº¬éƒ½ğŸ‡¯ğŸ‡µè²·ä¾†çš„ç¾é£Ÿ\\næŠ¹...|   529.0|  985|2023-04-14T09:30:10Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|_Kacv5GlJxg|  ã€å¾æ—¥æœ¬äº¬éƒ½ğŸ‡¯ğŸ‡µè²·ä¾†çš„ç¾é£Ÿã€‘æŠ¹...| 27302|     7| 0.03607794300783825|0.001574976192220...|\n",
      "|2023|    4| 14|   9|   Friday|  false|      ç¬‘æ³¢å­|      36|2023-04-16T09:38:...|        hd|          å¤ªç©ºæ‰“åœ°é¼ ï¼Ÿæ‰“Imposter? ...|    23.0|  441|2023-04-14T09:01:39Z|                       []|e1WRjaYgKJE|       ç©éæœ€æƒ¡æçš„Among UsğŸ˜³ï¼Ÿï¼Ÿï¼Ÿ|  9052|     0| 0.04871851524524967|0.003977021652673442|\n",
      "|2023|    4| 13|  11| Thursday|   true|      ç¬‘æ³¢å­|      42|2023-04-16T09:38:...|        hd|  ğŸ˜›å¹¾å¹´å¾Œå†ä¾†é€™é–“å¤¾å¨ƒå¨ƒåº—ï¼å¼˜å¤§çš„...|   380.0| 1333|2023-04-13T11:01:15Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|EFXej9P6xk4| ã€ğŸ˜›éŸ“åœ‹å¤¾å¨ƒå¨ƒå¤©å ‚ã€‘ç–«æƒ…å¾Œå†ä¾†â€¦...| 49480|     7|0.026940177849636218|8.488278092158447E-4|\n",
      "|2023|    4| 12|   9|Wednesday|  false|      ç¬‘æ³¢å­|      38|2023-04-16T09:38:...|        hd|           ç•¶Among Usè®ŠæˆçœŸäººåŒ–ğŸ˜ˆ?...|   631.0|  577|2023-04-12T09:00:34Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|o-lIiyrzy38|      Among UsçœŸäººåŒ–ï¼Ÿå®‡å®™ç‹¼äººæ®º...| 20068|     7|0.028752242375921867|0.001893561889575...|\n",
      "|2023|    4| 11|  12|  Tuesday|   true|      ç¬‘æ³¢å­|      90|2023-04-16T09:38:...|        hd|å¦‚æœæˆ‘åœ¨é¦™æ¸¯ã€Œåšé€™ä»¶äº‹ã€ä¾¿çŠ¯æ³•äº†ï¼Ÿ...|   485.0| 2097|2023-04-11T12:18:12Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|SFSJEZcFLsM|     æˆ‘åšäº†ã€ŒğŸ˜²åœ¨é¦™æ¸¯çŠ¯æ³•ğŸˆ²ã€......|103896|     7|0.020183645183645182|8.662508662508662E-4|\n",
      "|2023|    4| 11|  11|  Tuesday|  false|      ç¬‘æ³¢å­|      13|2023-04-16T09:38:...|        hd|               Doge simulator æŸ´ç‹—...|  7375.0|  407|2023-04-11T11:08:19Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|sn0m4w66ubE|     ã€ç‹—ç‹—ç‰ˆGTAğŸ¶ã€‘çˆ†ç¬‘æŸ´çŠ¬ğŸ¤£ç‚¸...| 15409|    12| 0.02641313518073853|8.436627944707638E-4|\n",
      "|2023|    4| 10|  10|   Monday|  false|      ç¬‘æ³¢å­|     146|2023-04-16T09:38:...|        hd|      æ˜ŸæœŸæ—¥å¥½å¤šå§å§è¡—ä¸Šè·³èˆğŸ’ƒ\\nğŸ˜³...|    60.0| 4142|2023-04-10T10:18:26Z|                       []|cc1BS62lZC0|ã€è¡—é ­æŒ‘æˆ°è·Ÿå§å§è·³èˆğŸ’ƒã€‘å®å®å™¹å™¹...| 67203|     0|0.061634153237206675|0.002172522060027082|\n",
      "|2023|    4| 10|   9|   Monday|  false|      ç¬‘æ³¢å­|       6|2023-04-16T09:38:...|        hd|             åŠ ç­å°ä¸Š: https://www...| 17712.0|  287|2023-04-10T09:26:57Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|DIBlgkT-xPk|  ã€å¾©æ´»ç¯€åŠ ç­å°(ä¸‹)ã€‘ğŸ˜±ç›´æ’­åˆ°å¤©...| 12294|    12|0.023344721002114852|4.880429477794046E-4|\n",
      "|2023|    4| 10|   7|   Monday|  false|      ç¬‘æ³¢å­|      66|2023-04-16T09:38:...|        hd|   å•ªå•ªå•ªä¹‹ç¥å†è‡¨ğŸ˜œ åˆå¯ä»¥æ—©åˆæ™šé£Ÿ...|   555.0| 1807|2023-04-10T07:41:39Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|nM-ZWw3e5cc|   ã€å¤¾å¨ƒå¨ƒã€‘ğŸ‡­ğŸ‡°é™å®šã€Œé¦™æ¸¯ä¹‹å…‰?...| 75475|     7|0.023941702550513415|8.744617422987744E-4|\n",
      "|2023|    4|  9|  20|   Sunday|  false|      ç¬‘æ³¢å­|      14|2023-04-16T09:38:...|        hd|           é‡‘ä¸»DONATEğŸ‘‰ğŸ»(æœƒè‡ªå‹•è®€...| 15169.0|  362|2023-04-09T20:47:00Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|8shhIhsX3hg|    ã€éµé´¨æ®º!!!!ã€‘ğŸ˜³ç”Ÿçœ¼æŒ‘é‡éƒ½è¦...| 16111|    12|0.022469120476692944|8.689715101483458E-4|\n",
      "|2023|    4|  8|   9| Saturday|   true|      ç¬‘æ³¢å­|     128|2023-04-16T09:38:...|        hd|  æ³¢å­ä¸€æ—¥åº—é•·ç³»åˆ—åˆä¾†å•¦ï¼\\nå¥½é–‹å¿ƒ...|   962.0| 2669|2023-04-08T09:00:00Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|-vvZF507BVE|       ã€ç¬‘æ³¢å­å†ãŠ™ï¸æ’ˆğŸ‘¨ğŸ»â€ğŸ’¼ã€‘ ...| 84002|     7|0.031773053022547085|0.001523773243494...|\n",
      "|2023|    4|  7|  20|   Friday|  false|      ç¬‘æ³¢å­|      18|2023-04-16T09:38:...|        hd|           é‡‘ä¸»DONATEğŸ‘‰ğŸ»(æœƒè‡ªå‹•è®€...| 21367.0|  513|2023-04-07T20:08:06Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|0F3_re_Cno0|ã€å¾©æ´»ç¯€åŠ ç­å°ã€‘ğŸ˜†ä½ çŒœæˆ‘ç•«ã€Œå¾©æ´»...| 23161|    12|0.022149302707136997|7.771685160398947E-4|\n",
      "|2023|    4|  7|   8|   Friday|   true|      ç¬‘æ³¢å­|     162|2023-04-16T09:38:...|        hd|    ç¬¬ä¸€å€‹é™¤ç½©å¾Œçš„æƒè¡—ï¼ (**æŒ‰è¨­å®š...|   994.0| 2864|2023-04-07T08:26:07Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|oVpnGKHy7qs|    ã€ğŸ˜›è‘µå»£ç¾é£Ÿæƒè¡—2023ã€‘é£Ÿç›¡æ–°...|135966|     7|0.021064089551799715|0.001191474339173...|\n",
      "|2023|    4|  6|   8| Thursday|  false|      ç¬‘æ³¢å­|      74|2023-04-16T09:38:...|        hd|  é–‰åº—è£ä¿®ä¸€å€‹å¤šæœˆå¾ŒğŸ”æœ‰ä»€éº¼è®ŠåŒ–ï¼Ÿ...|   497.0| 1575|2023-04-06T08:54:04Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|myNf93uFPp4|     ã€å¤¾å¨ƒå¨ƒã€‘æœ—è±ªåŠNamcoé‡é–‹ğŸ¤©...| 69080|     7|0.022799652576722642|0.001071221771858...|\n",
      "|2023|    4|  5|   8|Wednesday|  false|      ç¬‘æ³¢å­|      46|2023-04-16T09:38:...|        hd|            ç¬¨ç¬¨çš„æ­»æ³•DUMB WAYS TO...|   696.0| 1043|2023-04-05T08:51:52Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|_lI7y40LbFA|ã€ğŸ˜¨é˜»æ­¢æœ‹å‹è‡ªæ®ºçš„éŠæˆ²ï¼Ÿï¼ã€‘å¯æ˜¯...| 35960|     7|0.029004449388209123|0.001279199110122...|\n",
      "|2023|    4|  4|   7|  Tuesday|  false|      ç¬‘æ³¢å­|      70|2023-04-16T09:38:...|        hd|   å®Œæˆ100è¬è¨‚é–±ç¬¨è±¬è·³ä¹‹å‰ï¼Œç¬¬ä¸€æ¬¡...|   639.0| 1450|2023-04-04T07:15:06Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|ExFuS-VSE0M|   ã€æ¥µé™æŒ‘æˆ°ğŸ”¥ã€‘æˆ‘åœ¨600ç±³é«˜å±±ä¸Š...| 45426|     7| 0.03192004578875534|0.001540967727733...|\n",
      "|2023|    4|  3|   8|   Monday|   true|      ç¬‘æ³¢å­|      85|2023-04-16T09:38:...|        hd|    å–®è‰²å¤¾å¨ƒå¨ƒæŒ‘æˆ°åˆä¾†å•¦ï¼ğŸŒˆ\\nå¤§å®¶...|   351.0| 1326|2023-04-03T08:31:31Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|KC45-mFfhyQ|   ã€å¤¾å¨ƒå¨ƒã€‘ ğŸ’›é¡è‰²æŒ‘æˆ°ğŸŒæŠŠæ‰€æœ‰...| 55034|     7| 0.02409419631500527|0.001544499763782389|\n",
      "|2023|    4|  2|  17|   Sunday|  false|      ç¬‘æ³¢å­|       5|2023-04-16T09:38:...|        hd|               Hardcore~XD ä»²ä¿‚Har...|  7350.0|  292|2023-04-02T17:06:27Z|[ç¬‘æ³¢å­, æ³¢å­, hk, vlo...|H6qNZ6ZFxxI|             ã€Resident Evil 4æœ€...| 11872|    12|0.024595687331536387|4.211590296495957E-4|\n",
      "+----+-----+---+----+---------+-------+------------+--------+--------------------+----------+-------------------------------------+--------+-----+--------------------+-------------------------+-----------+-----------------------------------+------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size, array, when, col\n",
    "\n",
    "\n",
    "# Use when() function to replace null values with empty arrays\n",
    "df_allvideodetails0418 = df_allvideodetails0418.withColumn(\"Tags\", when(\n",
    "    df_allvideodetails0418.Tags.isNull(), array()).otherwise(df_allvideodetails0418.Tags))\n",
    "\n",
    "# Add a new column with array length\n",
    "df_allvideodetails0418 = df_allvideodetails0418.withColumn(\n",
    "    \"TagNum\", size(df_allvideodetails0418.Tags))\n",
    "\n",
    "# Replace -1 values with 0 in TagNum column\n",
    "df_allvideodetails0418 = df_allvideodetails0418.withColumn(\"TagNum\", when(\n",
    "    df_allvideodetails0418.TagNum == -1, 0).otherwise(df_allvideodetails0418.TagNum))\n",
    "\n",
    "# Add a new column 'likeRatio' with calculated values\n",
    "df_allvideodetails0418 = df_allvideodetails0418.withColumn(\"likeRatio\", col(\"Likes\") / col(\"Views\"))\n",
    "\n",
    "# Add a new column 'commentRatio' with calculated values\n",
    "df_allvideodetails0418 = df_allvideodetails0418.withColumn(\"commentRatio\", col(\"Comments\") / col(\"Views\"))\n",
    "\n",
    "# print the schema\n",
    "df_allvideodetails0418.printSchema()\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_allvideodetails0418.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write dataframe of allvideocomments without sentiment scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+--------------------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "|year|month|day|hour|  weekday|     DataRetrievedAt|                 _id|  commentPublishedAt|                          commentText|likeCount|    videoId|\n",
      "+----+-----+---+----+---------+--------------------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "|2023|    4|  7|   4|   Friday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-07T04:23:51Z|                           é•¿å¤§äº†è®¸å¤š|        0|WxTxeyqRM4E|\n",
      "|2023|    4|  6|  23| Thursday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-06T23:17:43Z|                           So cuteâ¤~~|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  5|   7|Wednesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-05T07:42:41Z|                   æœ€å¯æ„›çš„ä»£è¨€äººğŸ˜„ğŸ¥°|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  4|  14|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T14:00:06Z|                  Coffee Sweet å¥½å¾—æ„|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  4|  11|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T11:33:17Z|                         ä»”ä»”å¥½å¾—æ„ğŸ˜‚|        4|WxTxeyqRM4E|\n",
      "|2023|    4| 15|   3| Saturday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-15T03:50:00Z|       çœŸçš„å¸Œæœ›å¯ä»¥keepä½æ¯æ—¥åšâ‹¯â‹¯?...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 13|   1| Thursday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-13T01:07:21Z|   èƒ½å‡ºé«–é—œç¯€ä¼¸å±•ç‘œä¼½å—ï½ï¼Ÿ \\nä¹…å...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 11|  13|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-11T13:21:17Z|                         So relaxingâ¤|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 10|  19|   Monday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-10T19:11:18Z|                          å¤§æ„›å‘¢æ¢ç‰‡â¤|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   2|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T02:00:22Z|                 Happy Easter ğŸ°ğŸ£...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T01:59:54Z|                 Thank you for sha...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T01:59:26Z|               å¥½é–‹å¿ƒé™ªå¯¶è²å…¬ä¸»åšç‘œä¼½|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T01:53:45Z|æ—©ä¸Šä¸€èµ·åšå®Œä¸€çµ„å¾Œï¼Œå‰›ç¡é†’çš„ç·Šç¹ƒæ„Ÿ...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  8|   7| Saturday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-08T07:54:13Z|   æœ€è¿‘å¤ªå¿™æ²’æœ‰å¥½å¥½èªçœŸæ‹‰ç­‹\\nçœ‹åˆ°c...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  8|   7| Saturday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-08T07:51:13Z|                 Challenging for m...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  7|   4|   Friday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-07T04:18:21Z|       coffeeå§å§ è«‹æ±‚ä¸‹æ¬¡å¯ä»¥å‡ºä¸€...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  6|  14| Thursday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-06T14:21:48Z|         å—¨ coffee è€å¸ˆ æœ‰æ²¡æœ‰ç¡å‰...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  23|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T23:37:15Z|         Coffee å¥½ä¹…æ²¡å‡ºèƒŒéƒ¨è®­ç»ƒäº† ğŸ˜³|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  23|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T23:10:42Z|ä¸çŸ¥é“è€å¸«å¯ä¸å¯ä»¥åœ¨æ¯ä¸€å€‹å‹•ä½œçš„å‰›...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  21|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T21:41:49Z|             å¯ä»¥å‡ºè‚©é ¸æ‹‰ä¼¸çš„ç‘œä¼½å—ï¼Ÿ|        0|ibZ6t_lTTIA|\n",
      "+----+-----+---+----+---------+--------------------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-----+---+----+--------+--------------------+--------------------+--------------------+---------------------+---------+-----------+\n",
      "|year|month|day|hour| weekday|     DataRetrievedAt|                 _id|  commentPublishedAt|          commentText|likeCount|    videoId|\n",
      "+----+-----+---+----+--------+--------------------+--------------------+--------------------+---------------------+---------+-----------+\n",
      "|2023|    4| 15|   9|Saturday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-15T09:53:26Z| Do you have exerc...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 15|   9|Saturday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-15T09:37:06Z|         thanks girl!|        0|pgGoBihIUiU|\n",
      "|2023|    4| 15|   1|Saturday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-15T01:20:47Z|             Love itâ¤|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|  23|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T23:53:37Z|                   Me|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|  19|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T19:45:52Z| Yesss pleaseee mo...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|  19|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T19:21:14Z|               ğ•ğ•†ğ•|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|  19|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T19:20:59Z|                  Wow|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|  15|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T15:31:15Z| Hi emi. Please Ki...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|  14|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T14:37:14Z| We need more of t...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|   9|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T09:15:06Z| I enjoyed this wo...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|   2|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T02:50:17Z| Wow done maam\\nTh...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 14|   2|  Friday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-14T02:05:41Z| Who's sitting whi...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 13|  16|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T16:44:07Z| I like your all v...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 13|  15|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T15:55:39Z| Back to excercise...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 13|  12|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T12:52:36Z| thank you emi iam...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 13|  11|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T11:29:48Z| Hi,Emi!â™¡I like yo...|        0|pgGoBihIUiU|\n",
      "|2023|    4| 13|   9|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T09:47:31Z| Omg ğŸ‰ğŸ‰ğŸ‰....you...|        1|pgGoBihIUiU|\n",
      "|2023|    4| 13|   7|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T07:36:56Z|         Lost of fun.|        0|pgGoBihIUiU|\n",
      "|2023|    4| 13|   6|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T06:27:23Z|Youâ€™re so cuteï½ L...|        1|pgGoBihIUiU|\n",
      "|2023|    4| 13|   4|Thursday|2023-04-15T11:16:...|{643a8880332a3928...|2023-04-13T04:42:20Z| Morning workout b...|        1|pgGoBihIUiU|\n",
      "+----+-----+---+----+--------+--------------------+--------------------+--------------------+---------------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_allcommentsinfo_unwinded0415_coffee = spark.read.format('mongo').option(\n",
    "    'spark.mongodb.input.uri', 'mongodb://172.1.0.10/youtubedataapi0415.allcommentsinfo_unwinded').load()\n",
    "\n",
    "df_allcommentsinfo_unwinded0415_emi = spark.read.format('mongo').option(\n",
    "    'spark.mongodb.input.uri', 'mongodb://172.1.0.10/youtubedataapi0415.allcommentsinfo_unwinded2').load()\n",
    "\n",
    "df_allcommentsinfo_unwinded0415_coffee.createOrReplaceTempView(\n",
    "    'df_allcommentsinfo_unwinded0415_coffee')\n",
    "df_allcommentsinfo_unwinded0415_emi.createOrReplaceTempView(\n",
    "    'df_allcommentsinfo_unwinded0415_emi')\n",
    "\n",
    "df_allcommentsinfo_unwinded0415_coffee = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(year from df_allcommentsinfo_unwinded0415_coffee.commentPublishedAt) as year,\n",
    "        EXTRACT(month from df_allcommentsinfo_unwinded0415_coffee.commentPublishedAt) as month,\n",
    "        EXTRACT(day from df_allcommentsinfo_unwinded0415_coffee.commentPublishedAt) as day,\n",
    "        EXTRACT(hour from df_allcommentsinfo_unwinded0415_coffee.commentPublishedAt ) as hour,\n",
    "        date_format(df_allcommentsinfo_unwinded0415_coffee.commentPublishedAt, 'EEEE') as weekday,\n",
    "        *\n",
    "    FROM df_allcommentsinfo_unwinded0415_coffee\n",
    "\"\"\")\n",
    "\n",
    "df_allcommentsinfo_unwinded0415_emi = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(year from df_allcommentsinfo_unwinded0415_emi.commentPublishedAt) as year,\n",
    "        EXTRACT(month from df_allcommentsinfo_unwinded0415_emi.commentPublishedAt) as month,\n",
    "        EXTRACT(day from df_allcommentsinfo_unwinded0415_emi.commentPublishedAt) as day,\n",
    "        EXTRACT(hour from df_allcommentsinfo_unwinded0415_emi.commentPublishedAt ) as hour,\n",
    "        date_format(df_allcommentsinfo_unwinded0415_emi.commentPublishedAt, 'EEEE') as weekday,\n",
    "        *\n",
    "    FROM df_allcommentsinfo_unwinded0415_emi\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "df_allcommentsinfo_unwinded0415_coffee.show()\n",
    "df_allcommentsinfo_unwinded0415_emi.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+--------------------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "|year|month|day|hour|  weekday|     DataRetrievedAt|                 _id|  commentPublishedAt|                          commentText|likeCount|    videoId|\n",
      "+----+-----+---+----+---------+--------------------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "|2023|    4|  7|   4|   Friday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-07T04:23:51Z|                           é•¿å¤§äº†è®¸å¤š|        0|WxTxeyqRM4E|\n",
      "|2023|    4|  6|  23| Thursday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-06T23:17:43Z|                           So cuteâ¤~~|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  5|   7|Wednesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-05T07:42:41Z|                   æœ€å¯æ„›çš„ä»£è¨€äººğŸ˜„ğŸ¥°|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  4|  14|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T14:00:06Z|                  Coffee Sweet å¥½å¾—æ„|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  4|  11|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T11:33:17Z|                         ä»”ä»”å¥½å¾—æ„ğŸ˜‚|        4|WxTxeyqRM4E|\n",
      "|2023|    4| 15|   3| Saturday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-15T03:50:00Z|       çœŸçš„å¸Œæœ›å¯ä»¥keepä½æ¯æ—¥åšâ‹¯â‹¯?...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 13|   1| Thursday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-13T01:07:21Z|   èƒ½å‡ºé«–é—œç¯€ä¼¸å±•ç‘œä¼½å—ï½ï¼Ÿ \\nä¹…å...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 11|  13|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-11T13:21:17Z|                         So relaxingâ¤|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 10|  19|   Monday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-10T19:11:18Z|                          å¤§æ„›å‘¢æ¢ç‰‡â¤|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   2|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T02:00:22Z|                 Happy Easter ğŸ°ğŸ£...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T01:59:54Z|                 Thank you for sha...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T01:59:26Z|               å¥½é–‹å¿ƒé™ªå¯¶è²å…¬ä¸»åšç‘œä¼½|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-09T01:53:45Z|æ—©ä¸Šä¸€èµ·åšå®Œä¸€çµ„å¾Œï¼Œå‰›ç¡é†’çš„ç·Šç¹ƒæ„Ÿ...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  8|   7| Saturday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-08T07:54:13Z|   æœ€è¿‘å¤ªå¿™æ²’æœ‰å¥½å¥½èªçœŸæ‹‰ç­‹\\nçœ‹åˆ°c...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  8|   7| Saturday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-08T07:51:13Z|                 Challenging for m...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  7|   4|   Friday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-07T04:18:21Z|       coffeeå§å§ è«‹æ±‚ä¸‹æ¬¡å¯ä»¥å‡ºä¸€...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  6|  14| Thursday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-06T14:21:48Z|         å—¨ coffee è€å¸ˆ æœ‰æ²¡æœ‰ç¡å‰...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  23|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T23:37:15Z|         Coffee å¥½ä¹…æ²¡å‡ºèƒŒéƒ¨è®­ç»ƒäº† ğŸ˜³|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  23|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T23:10:42Z|ä¸çŸ¥é“è€å¸«å¯ä¸å¯ä»¥åœ¨æ¯ä¸€å€‹å‹•ä½œçš„å‰›...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  21|  Tuesday|2023-04-15T07:07:...|{643a546c332a3928...|2023-04-04T21:41:49Z|             å¯ä»¥å‡ºè‚©é ¸æ‹‰ä¼¸çš„ç‘œä¼½å—ï¼Ÿ|        0|ibZ6t_lTTIA|\n",
      "+----+-----+---+----+---------+--------------------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# merge the dataframes using union\n",
    "merged_df_allcommentsinfo_unwinded = df_allcommentsinfo_unwinded0415_coffee.union(\n",
    "    df_allcommentsinfo_unwinded0415_emi)\n",
    "\n",
    "# show the merged dataframe\n",
    "merged_df_allcommentsinfo_unwinded.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_allcommentsinfo_unwinded = merged_df_allcommentsinfo_unwinded.withColumnRenamed(\n",
    "    \"commentText\", \"Comment\")\n",
    "merged_df_allcommentsinfo_unwinded = merged_df_allcommentsinfo_unwinded.withColumnRenamed(\n",
    "    \"likeCount\", \"LikeCount\")\n",
    "merged_df_allcommentsinfo_unwinded = merged_df_allcommentsinfo_unwinded.withColumnRenamed(\n",
    "    \"commentPublishedAt\", \"CommentPublishedTime\")\n",
    "merged_df_allcommentsinfo_unwinded = merged_df_allcommentsinfo_unwinded.drop(\n",
    "    \"_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "|year|month|day|hour|  weekday|     DataRetrievedAt|CommentPublishedTime|                              Comment|LikeCount|    videoId|\n",
      "+----+-----+---+----+---------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "|2023|    4|  7|   4|   Friday|2023-04-15T07:07:...|2023-04-07T04:23:51Z|                           é•¿å¤§äº†è®¸å¤š|        0|WxTxeyqRM4E|\n",
      "|2023|    4|  6|  23| Thursday|2023-04-15T07:07:...|2023-04-06T23:17:43Z|                           So cuteâ¤~~|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  5|   7|Wednesday|2023-04-15T07:07:...|2023-04-05T07:42:41Z|                   æœ€å¯æ„›çš„ä»£è¨€äººğŸ˜„ğŸ¥°|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  4|  14|  Tuesday|2023-04-15T07:07:...|2023-04-04T14:00:06Z|                  Coffee Sweet å¥½å¾—æ„|        2|WxTxeyqRM4E|\n",
      "|2023|    4|  4|  11|  Tuesday|2023-04-15T07:07:...|2023-04-04T11:33:17Z|                         ä»”ä»”å¥½å¾—æ„ğŸ˜‚|        4|WxTxeyqRM4E|\n",
      "|2023|    4| 15|   3| Saturday|2023-04-15T07:07:...|2023-04-15T03:50:00Z|       çœŸçš„å¸Œæœ›å¯ä»¥keepä½æ¯æ—¥åšâ‹¯â‹¯?...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 13|   1| Thursday|2023-04-15T07:07:...|2023-04-13T01:07:21Z|   èƒ½å‡ºé«–é—œç¯€ä¼¸å±•ç‘œä¼½å—ï½ï¼Ÿ \\nä¹…å...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 11|  13|  Tuesday|2023-04-15T07:07:...|2023-04-11T13:21:17Z|                         So relaxingâ¤|        0|ibZ6t_lTTIA|\n",
      "|2023|    4| 10|  19|   Monday|2023-04-15T07:07:...|2023-04-10T19:11:18Z|                          å¤§æ„›å‘¢æ¢ç‰‡â¤|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   2|   Sunday|2023-04-15T07:07:...|2023-04-09T02:00:22Z|                 Happy Easter ğŸ°ğŸ£...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|2023-04-09T01:59:54Z|                 Thank you for sha...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|2023-04-09T01:59:26Z|               å¥½é–‹å¿ƒé™ªå¯¶è²å…¬ä¸»åšç‘œä¼½|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  9|   1|   Sunday|2023-04-15T07:07:...|2023-04-09T01:53:45Z|æ—©ä¸Šä¸€èµ·åšå®Œä¸€çµ„å¾Œï¼Œå‰›ç¡é†’çš„ç·Šç¹ƒæ„Ÿ...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  8|   7| Saturday|2023-04-15T07:07:...|2023-04-08T07:54:13Z|   æœ€è¿‘å¤ªå¿™æ²’æœ‰å¥½å¥½èªçœŸæ‹‰ç­‹\\nçœ‹åˆ°c...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  8|   7| Saturday|2023-04-15T07:07:...|2023-04-08T07:51:13Z|                 Challenging for m...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  7|   4|   Friday|2023-04-15T07:07:...|2023-04-07T04:18:21Z|       coffeeå§å§ è«‹æ±‚ä¸‹æ¬¡å¯ä»¥å‡ºä¸€...|        1|ibZ6t_lTTIA|\n",
      "|2023|    4|  6|  14| Thursday|2023-04-15T07:07:...|2023-04-06T14:21:48Z|         å—¨ coffee è€å¸ˆ æœ‰æ²¡æœ‰ç¡å‰...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  23|  Tuesday|2023-04-15T07:07:...|2023-04-04T23:37:15Z|         Coffee å¥½ä¹…æ²¡å‡ºèƒŒéƒ¨è®­ç»ƒäº† ğŸ˜³|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  23|  Tuesday|2023-04-15T07:07:...|2023-04-04T23:10:42Z|ä¸çŸ¥é“è€å¸«å¯ä¸å¯ä»¥åœ¨æ¯ä¸€å€‹å‹•ä½œçš„å‰›...|        0|ibZ6t_lTTIA|\n",
      "|2023|    4|  4|  21|  Tuesday|2023-04-15T07:07:...|2023-04-04T21:41:49Z|             å¯ä»¥å‡ºè‚©é ¸æ‹‰ä¼¸çš„ç‘œä¼½å—ï¼Ÿ|        0|ibZ6t_lTTIA|\n",
      "+----+-----+---+----+---------+--------------------+--------------------+-------------------------------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df_allcommentsinfo_unwinded.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write dataframe of allvideocomments with sentiment scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+--------+---------+-------------------+--------------------+\n",
      "|              Comment|CommentPublishedTime|Language|LikeCount|          Magnitude|               Score|\n",
      "+---------------------+--------------------+--------+---------+-------------------+--------------------+\n",
      "| Do you have exerc...|2023-04-15T09:53:26Z|      en|        0|0.10000000149011612|-0.10000000149011612|\n",
      "|         thanks girl!|2023-04-15T09:37:06Z|      en|        0| 0.8999999761581421|  0.8999999761581421|\n",
      "|             Love itâ¤|2023-04-15T01:20:47Z|      en|        0| 0.8999999761581421|  0.8999999761581421|\n",
      "|                   Me|2023-04-14T23:53:37Z|      en|        0|0.30000001192092896| 0.30000001192092896|\n",
      "| Yesss pleaseee mo...|2023-04-14T19:45:52Z|      en|        0| 0.4000000059604645|  0.4000000059604645|\n",
      "|               ğ•ğ•†ğ•|2023-04-14T19:21:14Z|      en|        0|0.30000001192092896| 0.30000001192092896|\n",
      "|                  Wow|2023-04-14T19:20:59Z|      en|        0| 0.8999999761581421|  0.8999999761581421|\n",
      "| Hi emi. Please Ki...|2023-04-14T15:31:15Z|      en|        0|0.30000001192092896| 0.10000000149011612|\n",
      "| We need more of t...|2023-04-14T14:37:14Z|      en|        0|  0.800000011920929|   0.800000011920929|\n",
      "| I enjoyed this wo...|2023-04-14T09:15:06Z|      en|        0| 0.8999999761581421|  0.8999999761581421|\n",
      "| Wow done maam\\nTh...|2023-04-14T02:50:17Z|      en|        0| 0.8999999761581421|  0.8999999761581421|\n",
      "| Who's sitting whi...|2023-04-14T02:05:41Z|      en|        0|                0.5|                 0.0|\n",
      "| I like your all v...|2023-04-13T16:44:07Z|      en|        0| 0.8999999761581421|  0.8999999761581421|\n",
      "| Back to excercise...|2023-04-13T15:55:39Z|      en|        0| 0.8999999761581421|  0.8999999761581421|\n",
      "| thank you emi iam...|2023-04-13T12:52:36Z|      en|        0|  1.100000023841858|                 0.5|\n",
      "| Hi,Emi!â™¡I like yo...|2023-04-13T11:29:48Z|      en|        0|  1.100000023841858|                 0.5|\n",
      "| Omg ğŸ‰ğŸ‰ğŸ‰....you...|2023-04-13T09:47:31Z|      en|        1| 0.8999999761581421|  0.8999999761581421|\n",
      "|         Lost of fun.|2023-04-13T07:36:56Z|      en|        0| 0.6000000238418579|  0.6000000238418579|\n",
      "|Youâ€™re so cuteï½ L...|2023-04-13T06:27:23Z|      en|        1| 0.8999999761581421|  0.8999999761581421|\n",
      "| Morning workout b...|2023-04-13T04:42:20Z|      en|        1| 0.4000000059604645|  0.4000000059604645|\n",
      "+---------------------+--------------------+--------+---------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_allcommentsinfo_unwinded_sentiment_coffee = spark.read.format('mongo').option(\n",
    "    'spark.mongodb.input.uri', 'mongodb://172.1.0.10/youtubedataapi0415.allcommentsinfo_unwinded_sentiment').load()\n",
    "\n",
    "df_allcommentsinfo_unwinded_sentiment_emi = spark.read.format('mongo').option(\n",
    "    'spark.mongodb.input.uri', 'mongodb://172.1.0.10/youtubedataapi0415.allcommentsinfo_unwinded_sentiment2').load()\n",
    "\n",
    "df_allcommentsinfo_unwinded_sentiment_coffee.createOrReplaceTempView(\n",
    "    'df_llcommentsinfo_unwinded_sentiment_coffee')\n",
    "df_allcommentsinfo_unwinded_sentiment_emi.createOrReplaceTempView(\n",
    "    'df_llcommentsinfo_unwinded_sentiment_emi')\n",
    "\n",
    "# merge the dataframes using union\n",
    "merged_df_allcommentsinfo_sentiment = df_allcommentsinfo_unwinded_sentiment_emi.union(\n",
    "    df_allcommentsinfo_unwinded_sentiment_coffee).drop(\"_id\")\n",
    "\n",
    "# show the merged dataframe\n",
    "merged_df_allcommentsinfo_sentiment.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine dataframes of allvideocommentsinfo and allvideocomments with sentiment scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Comment: string (nullable = true)\n",
      " |-- LikeCount: integer (nullable = true)\n",
      " |-- CommentPublishedTime: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- DataRetrievedAt: string (nullable = true)\n",
      " |-- videoId: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Magnitude: double (nullable = true)\n",
      " |-- Score: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----+-----+---+----+---------+--------------------+-----------+--------+-------------------+--------------------+\n",
      "|             Comment|LikeCount|CommentPublishedTime|year|month|day|hour|  weekday|     DataRetrievedAt|    videoId|Language|          Magnitude|               Score|\n",
      "+--------------------+---------+--------------------+----+-----+---+----+---------+--------------------+-----------+--------+-------------------+--------------------+\n",
      "|                    |        0|2017-11-05T17:54:55Z|2017|   11|  5|  17|   Sunday|2023-04-15T07:10:...|MdhbH0HNr2w|      en|                0.0|                 0.0|\n",
      "|                    |        0|2021-04-23T15:58:26Z|2021|    4| 23|  15|   Friday|2023-04-15T11:17:...|s4fwetu2Px4|      en|                0.0|                 0.0|\n",
      "|              åŠ æ²¹â›½ï¸|        1|2015-07-28T08:55:26Z|2015|    7| 28|   8|  Tuesday|2023-04-15T07:10:...|zT2jhR66ADo|      zh| 0.8999999761581421|  0.8999999761581421|\n",
      "|              !!ğŸ˜ğŸ‘Œ|        1|2017-06-15T13:18:09Z|2017|    6| 15|  13| Thursday|2023-04-15T11:19:...|ipUAWibHL34|      en|                0.5|                 0.5|\n",
      "|\" 1,2,3,4,5,6,7\\n...|        1|2022-03-13T22:25:45Z|2022|    3| 13|  22|   Sunday|2023-04-15T11:18:...|aIMfpvdOmX8|      en|0.10000000149011612| 0.10000000149011612|\n",
      "|\"1m63 and 110lbs\"...|        2|2020-05-25T13:46:26Z|2020|    5| 25|  13|   Monday|2023-04-15T11:19:...|frpjZ5sPR-A|      de|0.20000000298023224|-0.20000000298023224|\n",
      "|\"A\" in Love, marr...|        3|2021-07-08T12:52:35Z|2021|    7|  8|  12| Thursday|2023-04-15T11:17:...|MGHgcrjwF-0|      en|0.20000000298023224|-0.10000000149011612|\n",
      "|\"Baju\" means clot...|        0|2018-12-02T12:31:02Z|2018|   12|  2|  12|   Sunday|2023-04-15T11:18:...|Df64skVTGnU|      en|                0.0|                 0.0|\n",
      "|\"But seek first t...|        1|2021-06-09T13:03:49Z|2021|    6|  9|  13|Wednesday|2023-04-15T11:17:...|r_UDA3E0dtg|      en| 0.6000000238418579| 0.30000001192092896|\n",
      "|\"Closer the movem...|        1|2022-11-20T19:47:47Z|2022|   11| 20|  19|   Sunday|2023-04-15T11:18:...|6wEGUy9cTjs|      en| 0.6000000238418579| 0.30000001192092896|\n",
      "|\"Don't worry it i...|        9|2022-01-16T17:22:38Z|2022|    1| 16|  17|   Sunday|2023-04-15T11:17:...|VUVlYOsVf30|      en|  0.699999988079071|  -0.699999988079071|\n",
      "|\"En route\" ? Do y...|        1|2018-10-24T22:28:43Z|2018|   10| 24|  22|Wednesday|2023-04-15T11:18:...|UmRfx3a7OyE|      en|                0.0|                 0.0|\n",
      "|\"Extracuricular A...|       37|2018-06-29T22:32:21Z|2018|    6| 29|  22|   Friday|2023-04-15T11:19:...|xtdozPQbSv8|      en|  7.199999809265137|                 0.5|\n",
      "|\"For to me, to li...|        1|2021-06-07T03:31:49Z|2021|    6|  7|   3|   Monday|2023-04-15T11:17:...|r_UDA3E0dtg|      en|0.20000000298023224|                 0.0|\n",
      "|\"Girlfriend cant ...|        0|2019-11-15T08:32:45Z|2019|   11| 15|   8|   Friday|2023-04-15T11:18:...|afWSGNQJI7Y|      en|0.20000000298023224|-0.20000000298023224|\n",
      "|\"Hey! I'm Chad!\" ...|        0|2019-08-30T07:59:02Z|2019|    8| 30|   7|   Friday|2023-04-15T11:19:...|AjalM-2bPN4|      en|  0.800000011920929| 0.20000000298023224|\n",
      "|\"I want to look d...|        0|2022-08-29T04:04:35Z|2022|    8| 29|   4|   Monday|2023-04-15T11:17:...|vP_nQw1KH3k|      en| 0.6000000238418579| -0.6000000238418579|\n",
      "|\"I'm a classy guy...|        8|2018-11-10T12:48:04Z|2018|   11| 10|  12| Saturday|2023-04-15T11:18:...|dwIare9U1ZU|      en| 0.8999999761581421|  0.8999999761581421|\n",
      "|\"IF IT'S PAINING,...|        1|2023-04-15T10:21:08Z|2023|    4| 15|  10| Saturday|2023-04-15T11:17:...|jXm0y-csiuE|      en|0.10000000149011612|-0.10000000149011612|\n",
      "|\"It's her fantasy...|        3|2021-01-05T15:49:18Z|2021|    1|  5|  15|  Tuesday|2023-04-15T11:18:...|wX5IgKXmhXw|      en| 0.8999999761581421|  0.4000000059604645|\n",
      "+--------------------+---------+--------------------+----+-----+---+----+---------+--------------------+-----------+--------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# combine the dataframes using join\n",
    "combined_df_allcomments = merged_df_allcommentsinfo_unwinded.join(\n",
    "    merged_df_allcommentsinfo_sentiment, [\"Comment\", \"LikeCount\", \"CommentPublishedTime\"], \"outer\")\n",
    "\n",
    "# print the schema\n",
    "combined_df_allcomments.printSchema()\n",
    "# show the combined dataframe\n",
    "combined_df_allcomments.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# select only the necessary columns from df_allvideodetails0415\n",
    "df_allvideodetails0416_selected = df_allvideodetails0418.select(\n",
    "    \"videoId\", \"ChannelTitle\")\n",
    "\n",
    "# join the two dataframes on the videoId column\n",
    "joined_comment_df = combined_df_allcomments.join(\n",
    "    df_allvideodetails0416_selected, \"videoId\", \"left_outer\").drop(df_allvideodetails0416_selected.videoId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------+---------+--------------------+----+-----+---+----+---------+--------------------+--------+-------------------+--------------------+------------+\n",
      "|    videoId|                     Comment|LikeCount|CommentPublishedTime|year|month|day|hour|  weekday|     DataRetrievedAt|Language|          Magnitude|               Score|ChannelTitle|\n",
      "+-----------+----------------------------+---------+--------------------+----+-----+---+----+---------+--------------------+--------+-------------------+--------------------+------------+\n",
      "|vAPTEmKqywk|                           \"|        0|2022-03-12T07:11:17Z|2022|    3| 12|   7| Saturday|2023-04-15T11:16:...|      en|0.20000000298023224| 0.20000000298023224|    emi wong|\n",
      "|xtdozPQbSv8|        \" oh it's good fo...|        2|2018-06-29T16:35:46Z|2018|    6| 29|  16|   Friday|2023-04-15T11:19:...|      en| 0.8999999761581421|  0.8999999761581421|    emi wong|\n",
      "|FL_fAd_K720|        \"Don't just print...|       31|2020-10-31T14:54:30Z|2020|   10| 31|  14| Saturday|2023-04-15T11:19:...|      en|                0.5|                -0.5|    emi wong|\n",
      "|Ar9e8WBnYmg|\\bä¸€å¹´å‰æ— åšå®Œå‘¢ä¸ªchallen...|        0|2020-07-04T20:19:27Z|2020|    7|  4|  20| Saturday|2023-04-15T07:09:...|      zh| 0.8999999761581421|  0.8999999761581421|Coffeeæ—èŠŠå¦¤|\n",
      "|j8JUgvDaXAQ|        !!!i just LOVE YO...|        2|2018-06-23T20:45:48Z|2018|    6| 23|  20| Saturday|2023-04-15T11:19:...|      en|  1.899999976158142|  0.8999999761581421|    emi wong|\n",
      "|SUy3-htFkys|                          \\n|        0|2015-08-29T09:04:57Z|2015|    8| 29|   9| Saturday|2023-04-15T07:10:...|      en|                0.0|                 0.0|Coffeeæ—èŠŠå¦¤|\n",
      "|4MgHRtCZb40|        \"And we're awkwar...|       14|2018-09-30T13:14:46Z|2018|    9| 30|  13|   Sunday|2023-04-15T11:18:...|      en|  0.800000011920929|  -0.800000011920929|    emi wong|\n",
      "|yjlJiMNZDZA|                    !!!!!WOW|        1|2019-08-01T10:02:39Z|2019|    8|  1|  10| Thursday|2023-04-15T11:18:...|      en| 0.8999999761581421|  0.8999999761581421|    emi wong|\n",
      "|wMrLpFY38Yk|                            |        0|2023-03-26T08:17:23Z|2023|    3| 26|   8|   Sunday|2023-04-15T07:08:...|      en|                0.0|                 0.0|Coffeeæ—èŠŠå¦¤|\n",
      "|IhjFPldv0Ys|        \" too bad chad is...|        0|2020-04-20T11:45:55Z|2020|    4| 20|  11|   Monday|2023-04-15T11:18:...|      en|0.20000000298023224|-0.20000000298023224|    emi wong|\n",
      "|BRAZjn0HNis|        \"15 min NO JUMPIN...|       49|2020-06-09T21:11:19Z|2020|    6|  9|  21|  Tuesday|2023-04-15T11:19:...|      en|                0.5|-0.20000000298023224|    emi wong|\n",
      "|HXjlQQ4nWnc|        \"Can you trust th...|       15|2020-09-09T17:54:35Z|2020|    9|  9|  17|Wednesday|2023-04-15T11:17:...|      en|0.20000000298023224|-0.20000000298023224|    emi wong|\n",
      "|ipUAWibHL34|        \"Don't quit on me...|       54|2017-06-17T00:28:22Z|2017|    6| 17|   0| Saturday|2023-04-15T11:19:...|      en| 1.7000000476837158|  0.4000000059604645|    emi wong|\n",
      "|oivYJgfRkzY|        \" chad's boobs ca...|        0|2020-04-17T14:01:29Z|2020|    4| 17|  14|   Friday|2023-04-15T11:18:...|      en|0.20000000298023224| 0.20000000298023224|    emi wong|\n",
      "|r_UDA3E0dtg|        \"For God hath not...|        1|2021-06-21T11:41:25Z|2021|    6| 21|  11|   Monday|2023-04-15T11:17:...|      en|0.30000001192092896|-0.10000000149011612|    emi wong|\n",
      "|r_UDA3E0dtg|        \"For I know the p...|        1|2021-06-10T09:58:29Z|2021|    6| 10|   9| Thursday|2023-04-15T11:17:...|      en|0.20000000298023224| 0.10000000149011612|    emi wong|\n",
      "|r_UDA3E0dtg|        \"For everyone who...|        1|2021-06-08T03:38:43Z|2021|    6|  8|   3|  Tuesday|2023-04-15T11:17:...|      en|  0.800000011920929|  0.4000000059604645|    emi wong|\n",
      "|tCJ6IJaM9hU|        \"Do swimming\"\\n\\n...|        0|2021-06-07T12:05:52Z|2021|    6|  7|  12|   Monday|2023-04-15T11:19:...|      en|0.20000000298023224| 0.10000000149011612|    emi wong|\n",
      "|JYuT7hT7Ka8|        \"Ahh, this one ha...|       14|2017-11-08T13:33:32Z|2017|   11|  8|  13|Wednesday|2023-04-15T11:19:...|      en|  0.800000011920929|   0.800000011920929|    emi wong|\n",
      "|FIXgzH656dk|        \"Be Honest Who el...|       18|2020-06-24T14:09:25Z|2020|    6| 24|  14|Wednesday|2023-04-15T11:17:...|      en|                1.0|                 0.0|    emi wong|\n",
      "+-----------+----------------------------+---------+--------------------+----+-----+---+----+---------+--------------------+--------+-------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined_comment_df.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: write avro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_allcomments.write.format(\n",
    "    \"avro\").save(\"combined_df_allcomments.avro\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from spark to BigQuery\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write dataframe of allcomments_sentiment to BigQuery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "# configure BigQuery client\n",
    "client = bigquery.Client(project=\"spheric-temple-380502\")\n",
    "\n",
    "# create BigQuery table\n",
    "table_ref = client.dataset(\"youtubedata\").table(\n",
    "    \"allcomments_sentiment_0417\")\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"videoId\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Comment\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"LikeCount\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"CommentPublishedTime\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"year\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"month\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"day\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"hour\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"weekday\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"DataRetrievedAt\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Language\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Magnitude\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"Score\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"ChannelTitle\", \"STRING\"),\n",
    "]\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "# write the dataframe to BigQuery\n",
    "joined_comment_df.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"writeMethod\", \"direct\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save('spheric-temple-380502.youtubedata.allcomments_sentiment_0417')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write dataframe of allvideodetails to BigQuery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table spheric-temple-380502.youtubedata.allvideodetails0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "# configure BigQuery client\n",
    "client = bigquery.Client(project=\"spheric-temple-380502\")\n",
    "\n",
    "table_id = \"spheric-temple-380502.youtubedata.allvideodetails0416\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"Video_Title\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"year\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"month\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"day\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"hour\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"weekday\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Caption\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"ChannelTitle\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Comments\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"DataRetrievedAt\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Definition\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Description\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Duration\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"Likes\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"Published_date\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Tags\", \"STRING\", mode=\"REPEATED\"),\n",
    "    bigquery.SchemaField(\"VideoId\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Views\", \"INTEGER\")\n",
    "]\n",
    "\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "\n",
    "\n",
    "df_allvideodetails0418.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"writeMethod\", \"direct\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save('spheric-temple-380502.youtubedata.allvideodetails0416')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table spheric-temple-380502.youtubedata.allvideodetails0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# v2\n",
    "\n",
    "from google.cloud import bigquery\n",
    "# configure BigQuery client\n",
    "client = bigquery.Client(project=\"spheric-temple-380502\")\n",
    "\n",
    "table_id = \"spheric-temple-380502.youtubedata.allvideodetails0418\"\n",
    "\n",
    "schema = [\n",
    "    {\"name\": \"year\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"month\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"day\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"hour\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"weekday\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Caption\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"ChannelTitle\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Comments\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"DataRetrievedAt\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Definition\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Description\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Duration\", \"type\": \"FLOAT\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Likes\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Published_date\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Tags\", \"type\": \"STRING\", \"mode\": \"REPEATED\"},\n",
    "    {\"name\": \"VideoId\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"VideoTitle\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"Views\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"TagNum\", \"type\": \"INTEGER\", \"mode\": \"REQUIRED\"},\n",
    "    {\"name\": \"likeRatio\", \"type\": \"FLOAT\", \"mode\": \"NULLABLE\"},\n",
    "    {\"name\": \"commentRatio\", \"type\": \"FLOAT\", \"mode\": \"NULLABLE\"},\n",
    "]\n",
    "\n",
    "\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "\n",
    "\n",
    "df_allvideodetails0418.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"writeMethod\", \"direct\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save('spheric-temple-380502.youtubedata.allvideodetails0418')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
